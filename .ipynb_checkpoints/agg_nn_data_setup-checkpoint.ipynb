{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for preprocessing aggregate-format data to train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "agg_df = pd.read_csv('data_ready/agg/batting_norm_agg.csv')\n",
    "\n",
    "## get all the unique players in each class\n",
    "unique_not_hof_players = agg_df[agg_df['hof'] == False]['player_id'].unique()\n",
    "unique_hof_players = agg_df[agg_df['hof'] == True]['player_id'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test data by players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_player_not_hof = np.random.choice(unique_not_hof_players, size=(unique_not_hof_players.size*70)//100 , replace= False)\n",
    "test_player_not_hof = np.setdiff1d(unique_not_hof_players, training_player_not_hof) \n",
    "\n",
    "training_player_hof = np.random.choice(unique_hof_players, size=(unique_hof_players.size*70)//100 , replace= False)\n",
    "test_player_hof = np.setdiff1d(unique_hof_players, training_player_hof) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_player_not_hof = np.load('data_ready/agg/nn/train_non_hof.npy', allow_pickle=True)\n",
    "training_player_hof = np.load('data_ready/agg/nn/train_hof.npy', allow_pickle=True)\n",
    "test_player_not_hof = np.load('data_ready/agg/nn/test_non_hof.npy', allow_pickle=True)\n",
    "test_player_hof = np.load('data_ready/agg/nn/test_hof.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training and test data using the unique players above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = agg_df[agg_df['player_id'].isin(np.union1d(training_player_not_hof,training_player_hof))]\n",
    "test_data = agg_df[agg_df['player_id'].isin(np.union1d(test_player_not_hof, test_player_hof))]\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# replace the booleans with 1s and 0s\n",
    "test_data.loc[test_data['hof'] == False,'hof'] = 0\n",
    "test_data.loc[test_data['hof'] == True,'hof'] = 1\n",
    "training_data.loc[training_data['hof'] == False,'hof'] = 0\n",
    "training_data.loc[training_data['hof'] == True,'hof'] = 1\n",
    "\n",
    "# add a hof2 for cross entropy error\n",
    "test_data['hof2'] = 0\n",
    "test_data.loc[test_data['hof'] == 0,'hof2'] = 1\n",
    "training_data['hof2'] = 0\n",
    "training_data.loc[training_data['hof'] == 0,'hof2'] = 1\n",
    "\n",
    "# get rid of unwanted columns and get the np arrays\n",
    "redundant_columns = ['Unnamed: 0', 'Unnamed: 0.1','player_id','hof','hof2']\n",
    "\n",
    "test_numpy = test_data[test_data.columns.difference(redundant_columns)].to_numpy()\n",
    "train_numpy = training_data[training_data.columns.difference(redundant_columns)].to_numpy()\n",
    "\n",
    "test_labels = test_data[['hof','hof2']].to_numpy().astype(float)\n",
    "train_labels = training_data[['hof','hof2']].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the only last years data from test_data\n",
    "indexes = test_data.groupby(by='player_id')['years_played'].idxmax()\n",
    "\n",
    "last_years = test_data.loc[indexes]\n",
    "\n",
    "last_years_hof = last_years[last_years['hof'] == 1]\n",
    "last_years_hof_numpy = last_years_hof[last_years_hof.columns.difference(redundant_columns)].to_numpy()\n",
    "\n",
    "last_years_hof_labels =  last_years_hof[['hof','hof2']].to_numpy().astype(float)\n",
    "np.save(\"data_ready/agg/nn/last_years_hof.npy\",last_years_hof_numpy)\n",
    "np.save(\"data_ready/agg/nn/last_years_hof_labels.npy\",last_years_hof_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_years_numpy = last_years[last_years.columns.difference(redundant_columns)].to_numpy()\n",
    "last_years_labels =  last_years[['hof','hof2']].to_numpy().astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_ready/agg/nn/last_years.npy', last_years_numpy)\n",
    "np.save('data_ready/agg/nn/last_years_labels.npy', last_years_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data_ready/agg/nn/train_labels.npy\",train_labels)\n",
    "np.save(\"data_ready/agg/nn/test_labels.npy\",test_labels)\n",
    "np.save(\"data_ready/agg/nn/train_numpy.npy\",train_numpy)\n",
    "np.save(\"data_ready/agg/nn/test_numpy.npy\",test_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
