{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training time series models (ROCKET + Logistic Regression, LSTM, KNN, Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.read_csv('../data_ready/agg/batting_norm_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05280263669863359"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df['hof'].sum() / len(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agg2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7924880b0f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hof'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'agg2' is not defined"
     ]
    }
   ],
   "source": [
    "agg2[agg2['hof']].sort_values('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'robinja01' in agg_df['player_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ab</th>\n",
       "      <th>bb</th>\n",
       "      <th>double</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>hbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>player_id</th>\n",
       "      <th>r</th>\n",
       "      <th>rbi</th>\n",
       "      <th>sb</th>\n",
       "      <th>sh</th>\n",
       "      <th>so</th>\n",
       "      <th>triple</th>\n",
       "      <th>years_played</th>\n",
       "      <th>hof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>10801</td>\n",
       "      <td>11135</td>\n",
       "      <td>2.292722</td>\n",
       "      <td>2.240235</td>\n",
       "      <td>2.591963</td>\n",
       "      <td>1.998003</td>\n",
       "      <td>2.488705</td>\n",
       "      <td>6.671831</td>\n",
       "      <td>1.458201</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>3.642865</td>\n",
       "      <td>1.085564</td>\n",
       "      <td>8.566111</td>\n",
       "      <td>7.172417</td>\n",
       "      <td>1.011935</td>\n",
       "      <td>1.372121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>10802</td>\n",
       "      <td>11136</td>\n",
       "      <td>4.528465</td>\n",
       "      <td>3.784027</td>\n",
       "      <td>5.807126</td>\n",
       "      <td>3.911158</td>\n",
       "      <td>4.874066</td>\n",
       "      <td>11.659376</td>\n",
       "      <td>2.907315</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>6.579933</td>\n",
       "      <td>3.385108</td>\n",
       "      <td>14.241618</td>\n",
       "      <td>8.770737</td>\n",
       "      <td>2.109772</td>\n",
       "      <td>3.837238</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>10803</td>\n",
       "      <td>11137</td>\n",
       "      <td>6.872802</td>\n",
       "      <td>6.270096</td>\n",
       "      <td>9.143329</td>\n",
       "      <td>6.049299</td>\n",
       "      <td>7.872905</td>\n",
       "      <td>16.931551</td>\n",
       "      <td>4.877607</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>9.989135</td>\n",
       "      <td>7.031828</td>\n",
       "      <td>25.305467</td>\n",
       "      <td>12.920862</td>\n",
       "      <td>2.671748</td>\n",
       "      <td>8.007846</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>10804</td>\n",
       "      <td>11138</td>\n",
       "      <td>8.728852</td>\n",
       "      <td>8.537824</td>\n",
       "      <td>12.339013</td>\n",
       "      <td>7.864286</td>\n",
       "      <td>10.134893</td>\n",
       "      <td>19.422852</td>\n",
       "      <td>6.227248</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>12.395167</td>\n",
       "      <td>8.958394</td>\n",
       "      <td>29.002285</td>\n",
       "      <td>15.297901</td>\n",
       "      <td>2.959661</td>\n",
       "      <td>9.009622</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10805</th>\n",
       "      <td>10805</td>\n",
       "      <td>11139</td>\n",
       "      <td>10.818897</td>\n",
       "      <td>11.058990</td>\n",
       "      <td>15.184732</td>\n",
       "      <td>9.914692</td>\n",
       "      <td>12.817392</td>\n",
       "      <td>23.811590</td>\n",
       "      <td>8.553822</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>15.345945</td>\n",
       "      <td>11.442206</td>\n",
       "      <td>34.905238</td>\n",
       "      <td>16.415037</td>\n",
       "      <td>3.473955</td>\n",
       "      <td>11.468373</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>10806</td>\n",
       "      <td>11140</td>\n",
       "      <td>12.758883</td>\n",
       "      <td>14.898607</td>\n",
       "      <td>16.423240</td>\n",
       "      <td>11.920749</td>\n",
       "      <td>15.125007</td>\n",
       "      <td>30.566120</td>\n",
       "      <td>11.158136</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>18.559237</td>\n",
       "      <td>13.719215</td>\n",
       "      <td>41.542744</td>\n",
       "      <td>17.483768</td>\n",
       "      <td>4.469398</td>\n",
       "      <td>12.271331</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10807</th>\n",
       "      <td>10807</td>\n",
       "      <td>11141</td>\n",
       "      <td>14.412902</td>\n",
       "      <td>17.353990</td>\n",
       "      <td>19.174670</td>\n",
       "      <td>13.519523</td>\n",
       "      <td>17.184248</td>\n",
       "      <td>33.968164</td>\n",
       "      <td>12.244615</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>21.446999</td>\n",
       "      <td>16.219926</td>\n",
       "      <td>46.425804</td>\n",
       "      <td>19.576445</td>\n",
       "      <td>4.969051</td>\n",
       "      <td>14.478960</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>10808</td>\n",
       "      <td>11142</td>\n",
       "      <td>15.608180</td>\n",
       "      <td>19.261438</td>\n",
       "      <td>20.858504</td>\n",
       "      <td>14.899139</td>\n",
       "      <td>18.608473</td>\n",
       "      <td>37.697094</td>\n",
       "      <td>13.834982</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>22.872482</td>\n",
       "      <td>17.639577</td>\n",
       "      <td>48.154141</td>\n",
       "      <td>20.302901</td>\n",
       "      <td>5.014259</td>\n",
       "      <td>15.457645</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10809</th>\n",
       "      <td>10809</td>\n",
       "      <td>11143</td>\n",
       "      <td>16.581945</td>\n",
       "      <td>21.229693</td>\n",
       "      <td>20.927774</td>\n",
       "      <td>16.002269</td>\n",
       "      <td>19.475560</td>\n",
       "      <td>38.911168</td>\n",
       "      <td>14.400687</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>24.023981</td>\n",
       "      <td>18.326211</td>\n",
       "      <td>51.671887</td>\n",
       "      <td>21.717295</td>\n",
       "      <td>5.012603</td>\n",
       "      <td>15.831839</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10810</th>\n",
       "      <td>10810</td>\n",
       "      <td>11144</td>\n",
       "      <td>17.668698</td>\n",
       "      <td>23.066877</td>\n",
       "      <td>21.953706</td>\n",
       "      <td>17.236465</td>\n",
       "      <td>20.571717</td>\n",
       "      <td>39.927739</td>\n",
       "      <td>15.134438</td>\n",
       "      <td>robinja02</td>\n",
       "      <td>25.456372</td>\n",
       "      <td>19.202776</td>\n",
       "      <td>54.903839</td>\n",
       "      <td>23.830099</td>\n",
       "      <td>5.484345</td>\n",
       "      <td>16.115384</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1         ab         bb     double          g  \\\n",
       "10801       10801         11135   2.292722   2.240235   2.591963   1.998003   \n",
       "10802       10802         11136   4.528465   3.784027   5.807126   3.911158   \n",
       "10803       10803         11137   6.872802   6.270096   9.143329   6.049299   \n",
       "10804       10804         11138   8.728852   8.537824  12.339013   7.864286   \n",
       "10805       10805         11139  10.818897  11.058990  15.184732   9.914692   \n",
       "10806       10806         11140  12.758883  14.898607  16.423240  11.920749   \n",
       "10807       10807         11141  14.412902  17.353990  19.174670  13.519523   \n",
       "10808       10808         11142  15.608180  19.261438  20.858504  14.899139   \n",
       "10809       10809         11143  16.581945  21.229693  20.927774  16.002269   \n",
       "10810       10810         11144  17.668698  23.066877  21.953706  17.236465   \n",
       "\n",
       "               h        hbp         hr  player_id          r        rbi  \\\n",
       "10801   2.488705   6.671831   1.458201  robinja02   3.642865   1.085564   \n",
       "10802   4.874066  11.659376   2.907315  robinja02   6.579933   3.385108   \n",
       "10803   7.872905  16.931551   4.877607  robinja02   9.989135   7.031828   \n",
       "10804  10.134893  19.422852   6.227248  robinja02  12.395167   8.958394   \n",
       "10805  12.817392  23.811590   8.553822  robinja02  15.345945  11.442206   \n",
       "10806  15.125007  30.566120  11.158136  robinja02  18.559237  13.719215   \n",
       "10807  17.184248  33.968164  12.244615  robinja02  21.446999  16.219926   \n",
       "10808  18.608473  37.697094  13.834982  robinja02  22.872482  17.639577   \n",
       "10809  19.475560  38.911168  14.400687  robinja02  24.023981  18.326211   \n",
       "10810  20.571717  39.927739  15.134438  robinja02  25.456372  19.202776   \n",
       "\n",
       "              sb         sh        so     triple  years_played   hof  \n",
       "10801   8.566111   7.172417  1.011935   1.372121           1.0  True  \n",
       "10802  14.241618   8.770737  2.109772   3.837238           2.0  True  \n",
       "10803  25.305467  12.920862  2.671748   8.007846           3.0  True  \n",
       "10804  29.002285  15.297901  2.959661   9.009622           4.0  True  \n",
       "10805  34.905238  16.415037  3.473955  11.468373           5.0  True  \n",
       "10806  41.542744  17.483768  4.469398  12.271331           6.0  True  \n",
       "10807  46.425804  19.576445  4.969051  14.478960           7.0  True  \n",
       "10808  48.154141  20.302901  5.014259  15.457645           8.0  True  \n",
       "10809  51.671887  21.717295  5.012603  15.831839           9.0  True  \n",
       "10810  54.903839  23.830099  5.484345  16.115384          10.0  True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df[agg_df['player_id'] == 'robinja02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting stats to explore decision boundary (very messy for all pairs of stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbec6879190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg2 = agg_df.groupby('player_id').max('years_played')\n",
    "agg2.plot.scatter('r', 'hr', c=['red' if agg2.iloc[i]['hof'] else 'blue' for i in range(len(agg2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>bb</th>\n",
       "      <th>double</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>hbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>player_id</th>\n",
       "      <th>r</th>\n",
       "      <th>rbi</th>\n",
       "      <th>sb</th>\n",
       "      <th>sh</th>\n",
       "      <th>so</th>\n",
       "      <th>triple</th>\n",
       "      <th>years_played</th>\n",
       "      <th>hof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.661588</td>\n",
       "      <td>-0.438871</td>\n",
       "      <td>-0.640879</td>\n",
       "      <td>-0.705525</td>\n",
       "      <td>-0.583966</td>\n",
       "      <td>-0.539028</td>\n",
       "      <td>-0.388342</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.539369</td>\n",
       "      <td>-0.609924</td>\n",
       "      <td>-0.335788</td>\n",
       "      <td>-0.665060</td>\n",
       "      <td>-0.794309</td>\n",
       "      <td>-0.310270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.145500</td>\n",
       "      <td>-0.634319</td>\n",
       "      <td>-1.124076</td>\n",
       "      <td>-1.026475</td>\n",
       "      <td>-1.017650</td>\n",
       "      <td>-1.125153</td>\n",
       "      <td>-0.813317</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.903027</td>\n",
       "      <td>-1.153566</td>\n",
       "      <td>-0.636014</td>\n",
       "      <td>-1.424980</td>\n",
       "      <td>-0.892177</td>\n",
       "      <td>-0.404662</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.161406</td>\n",
       "      <td>-0.031041</td>\n",
       "      <td>-1.378979</td>\n",
       "      <td>-0.693510</td>\n",
       "      <td>-1.160762</td>\n",
       "      <td>-0.056680</td>\n",
       "      <td>-1.235447</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.879855</td>\n",
       "      <td>-1.079926</td>\n",
       "      <td>-0.389503</td>\n",
       "      <td>-1.058649</td>\n",
       "      <td>-1.112142</td>\n",
       "      <td>-0.762685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.954610</td>\n",
       "      <td>-0.615781</td>\n",
       "      <td>-2.052017</td>\n",
       "      <td>-1.647343</td>\n",
       "      <td>-1.893377</td>\n",
       "      <td>-0.604941</td>\n",
       "      <td>-1.638442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.575987</td>\n",
       "      <td>-1.775687</td>\n",
       "      <td>-0.956969</td>\n",
       "      <td>-1.764229</td>\n",
       "      <td>-2.108656</td>\n",
       "      <td>-1.364642</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.744661</td>\n",
       "      <td>-0.229190</td>\n",
       "      <td>-2.314481</td>\n",
       "      <td>-1.438181</td>\n",
       "      <td>-1.531243</td>\n",
       "      <td>-1.148788</td>\n",
       "      <td>-2.011442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.190280</td>\n",
       "      <td>-1.700775</td>\n",
       "      <td>-0.966303</td>\n",
       "      <td>-1.027140</td>\n",
       "      <td>-2.202136</td>\n",
       "      <td>-0.952990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43686</th>\n",
       "      <td>-0.448198</td>\n",
       "      <td>-0.350041</td>\n",
       "      <td>-0.506754</td>\n",
       "      <td>-0.542378</td>\n",
       "      <td>-0.443520</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>turnetr01</td>\n",
       "      <td>-0.407728</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.390894</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43687</th>\n",
       "      <td>0.781068</td>\n",
       "      <td>0.410928</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.614127</td>\n",
       "      <td>0.573732</td>\n",
       "      <td>0.309030</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>urshegi01</td>\n",
       "      <td>0.382690</td>\n",
       "      <td>0.258928</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>0.058954</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43688</th>\n",
       "      <td>-0.659393</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-1.099213</td>\n",
       "      <td>-0.623035</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>waldrky02</td>\n",
       "      <td>-0.605333</td>\n",
       "      <td>-0.587657</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.663400</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43689</th>\n",
       "      <td>-0.551088</td>\n",
       "      <td>-0.513105</td>\n",
       "      <td>-0.308580</td>\n",
       "      <td>-0.949296</td>\n",
       "      <td>-0.503358</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>willima07</td>\n",
       "      <td>-0.486770</td>\n",
       "      <td>-0.466716</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.613853</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43690</th>\n",
       "      <td>-0.491520</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-0.906462</td>\n",
       "      <td>-0.483412</td>\n",
       "      <td>-0.071749</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>willima08</td>\n",
       "      <td>-0.526291</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.489987</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43691 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ab        bb    double         g         h       hbp        hr  \\\n",
       "0     -0.661588 -0.438871 -0.640879 -0.705525 -0.583966 -0.539028 -0.388342   \n",
       "1     -1.145500 -0.634319 -1.124076 -1.026475 -1.017650 -1.125153 -0.813317   \n",
       "2     -1.161406 -0.031041 -1.378979 -0.693510 -1.160762 -0.056680 -1.235447   \n",
       "3     -1.954610 -0.615781 -2.052017 -1.647343 -1.893377 -0.604941 -1.638442   \n",
       "4     -1.744661 -0.229190 -2.314481 -1.438181 -1.531243 -1.148788 -2.011442   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "43686 -0.448198 -0.350041 -0.506754 -0.542378 -0.443520 -0.452528 -0.364299   \n",
       "43687  0.781068  0.410928  0.186854  0.614127  0.573732  0.309030  0.325219   \n",
       "43688 -0.659393 -0.567460 -0.605841 -1.099213 -0.623035 -0.452528 -0.502202   \n",
       "43689 -0.551088 -0.513105 -0.308580 -0.949296 -0.503358 -0.452528 -0.364299   \n",
       "43690 -0.491520 -0.567460 -0.605841 -0.906462 -0.483412 -0.071749 -0.502202   \n",
       "\n",
       "       player_id         r       rbi        sb        sh        so    triple  \\\n",
       "0      acostme01 -0.539369 -0.609924 -0.335788 -0.665060 -0.794309 -0.310270   \n",
       "1      acostme01 -0.903027 -1.153566 -0.636014 -1.424980 -0.892177 -0.404662   \n",
       "2      acostme01 -0.879855 -1.079926 -0.389503 -1.058649 -1.112142 -0.762685   \n",
       "3      acostme01 -1.575987 -1.775687 -0.956969 -1.764229 -2.108656 -1.364642   \n",
       "4      acostme01 -1.190280 -1.700775 -0.966303 -1.027140 -2.202136 -0.952990   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "43686  turnetr01 -0.407728 -0.547344  0.027295 -0.478008 -0.390894 -0.427949   \n",
       "43687  urshegi01  0.382690  0.258928 -0.357982  0.058954  0.748672  0.186402   \n",
       "43688  waldrky02 -0.605333 -0.587657 -0.357982 -0.478008 -0.663400 -0.427949   \n",
       "43689  willima07 -0.486770 -0.466716 -0.357982 -0.478008 -0.613853 -0.427949   \n",
       "43690  willima08 -0.526291 -0.547344 -0.357982 -0.478008 -0.489987  0.186402   \n",
       "\n",
       "       years_played    hof  \n",
       "0               1.0  False  \n",
       "1               2.0  False  \n",
       "2               3.0  False  \n",
       "3               4.0  False  \n",
       "4               5.0  False  \n",
       "...             ...    ...  \n",
       "43686           1.0  False  \n",
       "43687           1.0  False  \n",
       "43688           1.0  False  \n",
       "43689           1.0  False  \n",
       "43690           1.0  False  \n",
       "\n",
       "[43691 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_length = agg_df.groupby('player_id')['years_played'].max()\n",
    "players_5yrs = career_length[career_length > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg = np.load('train_numpy.npy')\n",
    "X_test_agg = np.load('test_numpy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup for time series classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load('../data_ready/ts/X_all.npy')\n",
    "y_all = np.load('../data_ready/y_all.npy')\n",
    "\n",
    "years_played_all = np.load('../data_ready/years_played_all.npy')\n",
    "player_ids_all = np.load('../data_ready/player_ids_all.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test split by HOF / non-hof players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_players = agg_df[agg_df['hof']]['player_id'].unique()\n",
    "non_hof_players = agg_df[~agg_df['hof']]['player_id'].unique()\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(hof_players), np.random.shuffle(non_hof_players);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_hof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-67dcc5e60d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_hof.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_non_hof.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_non\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_hof.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_non_hof.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_non\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_hof' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('train_hof.npy', train_hof)\n",
    "np.save('train_non_hof.npy', train_non)\n",
    "np.save('test_hof.npy', test_hof)\n",
    "np.save('test_non_hof.npy', test_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "zeros_ratio = 1\n",
    "n_hof, n_non = len(hof_players), len(non_hof_players)\n",
    "\n",
    "train_hof, test_hof = hof_players[:int(n_hof*train_ratio)], hof_players[int(n_hof*train_ratio):]\n",
    "train_non, test_non = non_hof_players[:int(n_non*train_ratio)], non_hof_players[int(n_non*train_ratio):]\n",
    "\n",
    "train_non_sample = train_non[:int(len(train_non)*zeros_ratio)]\n",
    "\n",
    "train_players, test_players = set(np.concatenate((train_hof, train_non_sample))), set(np.concatenate((test_hof, test_non)))\n",
    "\n",
    "train_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in train_players])\n",
    "test_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in test_players])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brownwi02', 'gehrich01', 'snidedu01', 'camparo01', 'sislege01',\n",
       "       'guerrvl01', 'gosligo01', 'perezto01', 'riceji01', 'winfida01',\n",
       "       'smithoz01', 'benchjo01', 'bankser01', 'martied01', 'bottoji01',\n",
       "       'lazzeto01', 'cronijo01', 'ripkeca01', 'traynpi01', 'morgajo02',\n",
       "       'manushe01', 'molitpa01', 'wilsoha01', 'reesepe01', 'simmoal01',\n",
       "       'ricesa01', 'gwynnto01', 'killeha01', 'robinfr02', 'heilmha01',\n",
       "       'jackstr01', 'irvinmo01', 'willibi01', 'kellyge01', 'mazerbi01',\n",
       "       'friscfr01', 'beltrad01', 'clemero01', 'applilu01'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_all[train_idxs], X_all[test_idxs]\n",
    "y_train, y_test = y_all[train_idxs], y_all[test_idxs]\n",
    "train_years_played, test_years_played = years_played_all[train_idxs], years_played_all[test_idxs]\n",
    "train_player_ids, test_player_ids = player_ids_all[train_idxs], player_ids_all[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation set as 10% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = train_idxs[:len(X_all) // 10]\n",
    "X_train, X_val = X_all[train_idxs[len(X_all) // 10:]], X_all[val_idxs]\n",
    "y_train, y_val = y_all[train_idxs[len(X_all) // 10:]], y_all[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hassaal01'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_player_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg_train, X_agg_test = X_train.sum(axis=1), X_test.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66158751, -0.43887093, -0.6408787 , ..., -0.66506004,\n",
       "        -0.79430897, -0.31026952],\n",
       "       [-1.14549996, -0.63431935, -1.12407567, ..., -1.42497997,\n",
       "        -0.89217663, -0.40466168],\n",
       "       [-1.16140608, -0.03104119, -1.37897893, ..., -1.05864942,\n",
       "        -1.1121419 , -0.76268502],\n",
       "       ...,\n",
       "       [-1.13874608, -1.17577685, -1.11938739, ..., -0.9802432 ,\n",
       "        -1.05790769, -0.83236857],\n",
       "       [-0.53840061, -0.58314743, -0.40956142, ..., -0.49427995,\n",
       "        -0.48063385, -0.41171796],\n",
       "       [-0.63583384, -0.52824339, -0.60625819, ..., -0.49427995,\n",
       "        -0.57991583, -0.41171796]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_agg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_agg_train, y_agg_test = to_categorical(y_train), to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data_ready/test_player_ids.npy', test_player_ids)\n",
    "np.save('../data_ready/test_years_played.npy', test_years_played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data_ready/ts/X_train.npy', X_train)\n",
    "np.save('../data_ready/ts/X_test.npy', X_test)\n",
    "np.save('../data_ready/y_train.npy', y_train)\n",
    "np.save('../data_ready/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undo zero-padding + group idxs by # of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unpad, X_test_unpad = [], []\n",
    "idx_train_by_year, idx_test_by_year = [[] for _ in range(26)], [[] for _ in range(26)]\n",
    "for i in range(X_train.shape[0]):\n",
    "    yrs_played = int(train_years_played[i])\n",
    "    idx_train_by_year[yrs_played].append(i)\n",
    "    X_train_unpad.append(X_train[i][:yrs_played])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yrs_played = int(test_years_played[i])\n",
    "    idx_test_by_year[yrs_played].append(i)\n",
    "    X_test_unpad.append(X_test[i][:yrs_played])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of HOFers + # of samples for each career length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04365079365079365, 2016),\n",
       " (0.05648267008985879, 1558),\n",
       " (0.0682699767261443, 1289),\n",
       " (0.08014571948998178, 1098),\n",
       " (0.09292502639915523, 947),\n",
       " (0.10438908659549229, 843),\n",
       " (0.11780455153949129, 747),\n",
       " (0.13273001508295626, 663),\n",
       " (0.1543859649122807, 570),\n",
       " (0.1825726141078838, 482),\n",
       " (0.2119700748129676, 401),\n",
       " (0.24561403508771928, 342),\n",
       " (0.31297709923664124, 262),\n",
       " (0.34101382488479265, 217),\n",
       " (0.39325842696629215, 178),\n",
       " (0.4701492537313433, 134),\n",
       " (0.5263157894736842, 114),\n",
       " (0.6710526315789473, 76),\n",
       " (0.7543859649122807, 57),\n",
       " (0.9166666666666666, 36),\n",
       " (0.9615384615384616, 26),\n",
       " (1.0, 18),\n",
       " (1.0, 8),\n",
       " (1.0, 3),\n",
       " (1.0, 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-170-ff41d8fec79c>:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.018095238095238095, 2100),\n",
       " (0.023125, 1600),\n",
       " (0.028136882129277566, 1315),\n",
       " (0.03268551236749117, 1132),\n",
       " (0.03707414829659319, 998),\n",
       " (0.041666666666666664, 888),\n",
       " (0.04798962386511025, 771),\n",
       " (0.0549777117384844, 673),\n",
       " (0.060810810810810814, 592),\n",
       " (0.0728744939271255, 494),\n",
       " (0.08333333333333333, 420),\n",
       " (0.10174418604651163, 344),\n",
       " (0.12546125461254612, 271),\n",
       " (0.1588785046728972, 214),\n",
       " (0.19642857142857142, 168),\n",
       " (0.22962962962962963, 135),\n",
       " (0.25742574257425743, 101),\n",
       " (0.30434782608695654, 69),\n",
       " (0.37209302325581395, 43),\n",
       " (0.4444444444444444, 27),\n",
       " (0.5384615384615384, 13),\n",
       " (0.4, 10),\n",
       " (0.3333333333333333, 3),\n",
       " (0.0, 1),\n",
       " (nan, 0)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training data')\n",
    "train_hist = [(np.sum(y_train[idx_train_by_year[i]]) / len(idx_train_by_year[i]), len(idx_train_by_year[i])) for i in range(1, 26)]\n",
    "display(train_hist)\n",
    "print('test data')\n",
    "test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n",
    "test_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random HOF and non-HOF samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "hof_rand, non_hof_rand = np.random.choice(np.where(y_train == 1)[0]), np.random.choice(np.where(y_train == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1397146 ,  2.02168166,  1.67783737,  1.08165126,  0.79330746,\n",
       "         0.4307195 ,  1.43247401,  1.64431773,  0.89903381,  3.21099742,\n",
       "         0.01175137,  2.02244887,  0.97868075],\n",
       "       [ 1.83910241,  1.49446174,  2.36819163,  1.85646077,  1.6838071 ,\n",
       "         0.92022933,  2.13481438,  2.35548097,  1.15177433,  2.77268543,\n",
       "        -0.66056693,  1.58710637,  3.81924303]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bondsba01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.74951754, -0.66633881, -0.60523593, -0.95311561, -0.67348963,\n",
       "        -0.56572792, -0.42212953, -0.69881213, -0.68285082, -0.57575304,\n",
       "        -0.75457976, -1.0194754 , -0.35802334]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'kolseka01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in (hof_rand, non_hof_rand):\n",
    "    display(X_train_unpad[i], train_years_played[i], train_player_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROCKET Transform + SGD Logistic Regression\n",
    "hinge: train in 70 sec, 90 epochs  \n",
    "log: train in 150 sec, 101 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Trying 70/30 splits because 80/20 gives too few 'full career' test samples of HOFers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sktime.transformers.series_as_features.rocket import Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket(rocket_pipeline, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Returns partitioned predictions and scores for \"1\" and \"0\" classes in the given test dataset\n",
    "    \"\"\"\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "        ones_preds = rocket_pipeline.predict(X_test[y_test == 1])\n",
    "        ones_score = np.sum(ones_preds) / len(ones_preds)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        zeros_preds = rocket_pipeline.predict(X_test[y_test == 0])\n",
    "        zeros_score = np.sum(1-zeros_preds) / len(zeros_preds)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket_by_year(rocket_pipeline, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "    \"\"\"\n",
    "    Returns result of eval_rocket, run on all samples that represent stats up to years_before_end years before the end of any player's career\n",
    "    \"\"\"\n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "        if years_before_end == 0:\n",
    "            print(classification_report(y_test_full_careers[idxs], rocket_pipeline.predict(X_test_full_careers[idxs])))\n",
    "            print(percent_fp_got_votes(y_test_full_careers[idxs], rocket_pipeline.predict(X_test_full_careers[idxs]), test_player_ids[test_idxs_full_careers][idxs]))\n",
    "        \n",
    "        return eval_rocket(rocket_pipeline, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_rocket(rocket_pipeline, X_test, y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_sgd = make_pipeline(Rocket(), SGDClassifier(loss='log', eta0=0.001, learning_rate='adaptive', verbose=1, class_weight={0:0.05, 1:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99043063e-01, 9.56937285e-04],\n",
       "       [9.99991698e-01, 8.30186029e-06],\n",
       "       [1.00000000e+00, 4.72711754e-11],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.46420600e-13],\n",
       "       [1.00000000e+00, 1.01084647e-11],\n",
       "       [9.99999990e-01, 9.65981292e-09]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = rocket_pipeline_sgd.predict(X_val)\n",
    "_, _, val_ones_score, val_zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_val, y_val, agg_df, test_player_ids, test_years_played, years_before_end=0)\n",
    "val_ones_score, val_zeros_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rocket_pipeline_sgd.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2062\n",
      "           1       0.15      0.26      0.19        38\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.57      0.62      0.59      2100\n",
      "weighted avg       0.97      0.96      0.97      2100\n",
      "\n",
      "0.14545454545454545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.2631578947368421, 38), (0.9733268671193016, 2062))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=0)\n",
    "ones_score, zeros_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_outputs/preds_rocket.npy', np.argmax(preds, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print ROCKET results for all values years_before_end values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2062\n",
      "           1       0.15      0.26      0.19        38\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.57      0.62      0.59      2100\n",
      "weighted avg       0.97      0.96      0.97      2100\n",
      "\n",
      "0.14545454545454545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0.2631578947368421, 38),\n",
       "  (0.2702702702702703, 37),\n",
       "  (0.24324324324324326, 37),\n",
       "  (0.2702702702702703, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.1891891891891892, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.1111111111111111, 36),\n",
       "  (0.1111111111111111, 36),\n",
       "  (0.11428571428571428, 35),\n",
       "  (0.05714285714285714, 35),\n",
       "  (0.11764705882352941, 34),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.06060606060606061, 33),\n",
       "  (0.0967741935483871, 31),\n",
       "  (0.0, 26),\n",
       "  (0.09523809523809523, 21),\n",
       "  (0.0625, 16),\n",
       "  (0.0, 12),\n",
       "  (0.14285714285714285, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9733268671193016, 2062),\n",
       "  (0.981445937300064, 1563),\n",
       "  (0.9710485133020345, 1278),\n",
       "  (0.971689497716895, 1095),\n",
       "  (0.9791883454734651, 961),\n",
       "  (0.9706227967097533, 851),\n",
       "  (0.9713896457765667, 734),\n",
       "  (0.970125786163522, 636),\n",
       "  (0.9622302158273381, 556),\n",
       "  (0.9606986899563319, 458),\n",
       "  (0.9402597402597402, 385),\n",
       "  (0.9546925566343042, 309),\n",
       "  (0.9662447257383966, 237),\n",
       "  (0.9722222222222222, 180),\n",
       "  (0.9407407407407408, 135),\n",
       "  (0.9423076923076923, 104),\n",
       "  (0.9066666666666666, 75),\n",
       "  (0.875, 48),\n",
       "  (0.9259259259259259, 27),\n",
       "  (1.0, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_preds, zeros_preds, ones_scores, zeros_scores = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores.append(ones_score), zeros_scores.append(zeros_score)\n",
    "    ones_preds.append(ones_pred), zeros_preds.append(zeros_pred)\n",
    "ones_scores, zeros_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "#### best settings: all 0s, class weight 0.05, 50 epochs, LSTM 20, Dense 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Construct an LSTM model and train it using the given dataset\n",
    "    \"\"\"\n",
    "    verbose, epochs, batch_size = 1, 50, 64\n",
    "    ts_length, n_features, n_classes = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    # model architecture\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=(ts_length, n_features)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax')) # softmax to output probabilities between 0 and 1\n",
    "    \n",
    "    # Adam learning rate optimizer, cross-entropy loss\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, class_weight={0:0.05, 1:1.0})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm(lstm, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Return predictions and accuracies for the given LSTM model, partitioned by label class\n",
    "    \"\"\"\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "#         print('ones ({})'.format(np.sum(y_test)))\n",
    "        ones_preds = lstm.predict(X_test[y_test == 1], batch_size=64, verbose=0)\n",
    "\n",
    "        ones_score = np.sum(np.argmax(ones_preds, axis=1)) / len(ones_preds)\n",
    "#         print(ones_score)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "#         print('zeros ({})'.format(np.sum(1-y_test)))\n",
    "        zeros_preds = lstm.predict(X_test[y_test == 0], batch_size=64, verbose=0)\n",
    "        zeros_score = np.sum(1-np.argmax(zeros_preds, axis=1)) / len(zeros_preds)\n",
    "#         print(zeros_score)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "     \"\"\"\n",
    "    Returns result of eval_lstm, run on all samples that represent stats up to years_before_end years before the end of any player's career\n",
    "    \"\"\"\n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "        if years_before_end == 0:\n",
    "            print(classification_report(y_test_full_careers[idxs], np.argmax(lstm.predict(X_test_full_careers[idxs]), axis=1)))\n",
    "            print(percent_fp_got_votes(y_test_full_careers[idxs], np.argmax(lstm.predict(X_test_full_careers[idxs]), axis=1), test_player_ids[test_idxs_full_careers][idxs]))\n",
    "        return eval_lstm(lstm, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_lstm(lstm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05647294302666381"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio of \"1\"s in training data\n",
    "sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0306 - accuracy: 0.6612\n",
      "Epoch 2/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0244 - accuracy: 0.7547\n",
      "Epoch 3/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0225 - accuracy: 0.7888\n",
      "Epoch 4/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0211 - accuracy: 0.7949\n",
      "Epoch 5/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0204 - accuracy: 0.8088\n",
      "Epoch 6/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0200 - accuracy: 0.8177\n",
      "Epoch 7/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0190 - accuracy: 0.8233\n",
      "Epoch 8/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.8415\n",
      "Epoch 9/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0176 - accuracy: 0.8459\n",
      "Epoch 10/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0176 - accuracy: 0.8518\n",
      "Epoch 11/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0171 - accuracy: 0.8570\n",
      "Epoch 12/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0172 - accuracy: 0.8576\n",
      "Epoch 13/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0161 - accuracy: 0.8685\n",
      "Epoch 14/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8732\n",
      "Epoch 15/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.8595\n",
      "Epoch 16/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0188 - accuracy: 0.8379\n",
      "Epoch 17/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0153 - accuracy: 0.8792\n",
      "Epoch 18/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0152 - accuracy: 0.8800\n",
      "Epoch 19/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.8982\n",
      "Epoch 20/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.8973\n",
      "Epoch 21/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0157 - accuracy: 0.8810\n",
      "Epoch 22/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0144 - accuracy: 0.8957\n",
      "Epoch 23/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0151 - accuracy: 0.8870\n",
      "Epoch 24/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9019\n",
      "Epoch 25/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9108\n",
      "Epoch 26/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9052\n",
      "Epoch 27/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9008\n",
      "Epoch 28/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9149\n",
      "Epoch 30/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9075\n",
      "Epoch 31/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.8927\n",
      "Epoch 32/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9173\n",
      "Epoch 33/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0147 - accuracy: 0.8805\n",
      "Epoch 34/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9065\n",
      "Epoch 35/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0130 - accuracy: 0.9107\n",
      "Epoch 36/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0130 - accuracy: 0.9094\n",
      "Epoch 37/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9114\n",
      "Epoch 38/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9138\n",
      "Epoch 39/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0118 - accuracy: 0.9180\n",
      "Epoch 40/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9149\n",
      "Epoch 41/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.8962\n",
      "Epoch 42/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9137\n",
      "Epoch 43/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9151\n",
      "Epoch 44/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9076\n",
      "Epoch 45/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9219\n",
      "Epoch 46/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9352\n",
      "Epoch 47/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9328\n",
      "Epoch 48/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9344\n",
      "Epoch 49/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9251\n",
      "Epoch 50/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "lstm = train_model(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lstm_by_year(lstm, X_val, y_val, agg_df, test_player_ids, test_years_played, years_before_end=1)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9459459459459459, 37), (0.889955214331414, 1563))"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=1)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      2138\n",
      "           1       0.29      0.72      0.42       144\n",
      "\n",
      "    accuracy                           0.87      2282\n",
      "   macro avg       0.64      0.80      0.67      2282\n",
      "weighted avg       0.94      0.87      0.90      2282\n",
      "\n",
      "0.13545816733067728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7222222222222222, 144), (0.882600561272217, 2138))"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, o, z = eval_lstm_by_year(lstm, X_test, y_test, agg_df, train_player_ids, train_years_played, years_before_end=0)\n",
    "o, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_outputs/probs_lstm.npy', probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_fp_got_votes(y_true, y_preds, idx_player_ids): # about half\n",
    "    \"\"\"\n",
    "    Returns the ratio of the false-positive predicted samples that were ever on the Hall of Fame Ballot\n",
    "    \n",
    "    This statistic is interesting because being on the ballot implies that a player is near the real-world decision boundary; \n",
    "        if a model has a higher ratio here, that means that its false positives were still reasonable predictions.\n",
    "    \"\"\"\n",
    "    fp_idxs = np.where((y_true == 0) & (y_preds == 1))[0]\n",
    "    fp_players = idx_player_ids[fp_idxs]\n",
    "    hof = pd.read_csv('../data_normalized/hall_of_fame.csv')\n",
    "    return np.mean(np.isin(fp_players, hof['player_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      2062\n",
      "           1       0.27      0.79      0.41        38\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.63      0.88      0.69      2100\n",
      "weighted avg       0.98      0.96      0.97      2100\n",
      "\n",
      "0.475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0.7894736842105263, 38),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8108108108108109, 37),\n",
       "  (0.8108108108108109, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8648648648648649, 37),\n",
       "  (0.7567567567567568, 37),\n",
       "  (0.75, 36),\n",
       "  (0.7222222222222222, 36),\n",
       "  (0.7428571428571429, 35),\n",
       "  (0.6857142857142857, 35),\n",
       "  (0.6470588235294118, 34),\n",
       "  (0.7352941176470589, 34),\n",
       "  (0.6060606060606061, 33),\n",
       "  (0.5806451612903226, 31),\n",
       "  (0.4230769230769231, 26),\n",
       "  (0.47619047619047616, 21),\n",
       "  (0.5, 16),\n",
       "  (0.5, 12),\n",
       "  (0.2857142857142857, 7),\n",
       "  (0.25, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9612027158098934, 2062),\n",
       "  (0.9321817018554063, 1563),\n",
       "  (0.9100156494522692, 1278),\n",
       "  (0.8849315068493151, 1095),\n",
       "  (0.8626430801248699, 961),\n",
       "  (0.8401880141010576, 851),\n",
       "  (0.8501362397820164, 734),\n",
       "  (0.8380503144654088, 636),\n",
       "  (0.8165467625899281, 556),\n",
       "  (0.8013100436681223, 458),\n",
       "  (0.787012987012987, 385),\n",
       "  (0.7928802588996764, 309),\n",
       "  (0.7890295358649789, 237),\n",
       "  (0.8111111111111111, 180),\n",
       "  (0.7851851851851852, 135),\n",
       "  (0.7788461538461539, 104),\n",
       "  (0.84, 75),\n",
       "  (0.8333333333333334, 48),\n",
       "  (0.8518518518518519, 27),\n",
       "  (0.9333333333333333, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (0.5, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for all valid values of years_before_end\n",
    "ones_preds_lstm, zeros_preds_lstm, ones_scores_lstm, zeros_scores_lstm = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores_lstm.append(ones_score), zeros_scores_lstm.append(zeros_score)\n",
    "    ones_preds_lstm.append(ones_pred), zeros_preds_lstm.append(zeros_pred)\n",
    "ones_scores_lstm, zeros_scores_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.96      0.98      2062\n",
    "               1       0.27      0.79      0.41        38\n",
    "\n",
    "        accuracy                           0.96      2100\n",
    "       macro avg       0.63      0.88      0.69      2100\n",
    "    weighted avg       0.98      0.96      0.97      2100\n",
    "better_lstm ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.93      0.97      2062\n",
    "               1       0.20      0.92      0.33        38\n",
    "\n",
    "        accuracy                           0.93      2100\n",
    "       macro avg       0.60      0.93      0.65      2100\n",
    "    weighted avg       0.98      0.93      0.95      2100\n",
    "    \n",
    "better_lstm ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.9210526315789473, 38),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.8918918918918919, 37),\n",
       "  (0.918918918918919, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8333333333333334, 36),\n",
       "  (0.8055555555555556, 36),\n",
       "  (0.8, 35),\n",
       "  (0.7428571428571429, 35),\n",
       "  (0.7058823529411765, 34),\n",
       "  (0.7352941176470589, 34),\n",
       "  (0.5454545454545454, 33),\n",
       "  (0.5483870967741935, 31),\n",
       "  (0.38461538461538464, 26),\n",
       "  (0.42857142857142855, 21),\n",
       "  (0.4375, 16),\n",
       "  (0.5, 12),\n",
       "  (0.42857142857142855, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9340446168768186, 2062),\n",
       "  (0.889955214331414, 1563),\n",
       "  (0.8544600938967136, 1278),\n",
       "  (0.8356164383561644, 1095),\n",
       "  (0.7960457856399584, 961),\n",
       "  (0.7861339600470035, 851),\n",
       "  (0.7806539509536785, 734),\n",
       "  (0.7625786163522013, 636),\n",
       "  (0.7661870503597122, 556),\n",
       "  (0.7663755458515283, 458),\n",
       "  (0.7688311688311689, 385),\n",
       "  (0.7346278317152104, 309),\n",
       "  (0.7426160337552743, 237),\n",
       "  (0.7777777777777778, 180),\n",
       "  (0.7703703703703704, 135),\n",
       "  (0.7884615384615384, 104),\n",
       "  (0.8133333333333334, 75),\n",
       "  (0.8125, 48),\n",
       "  (0.8148148148148148, 27),\n",
       "  (0.8666666666666667, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (0.5, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores_lstm, zeros_scores_lstm # lstm25, dense50, 50 epoch, .05 0s weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5569341e-01, 3.4430656e-01],\n",
       "       [8.2225472e-01, 1.7774528e-01],\n",
       "       [1.4185956e-01, 8.5814047e-01],\n",
       "       [9.7852433e-03, 9.9021471e-01],\n",
       "       [6.7260936e-03, 9.9327385e-01],\n",
       "       [4.9038115e-03, 9.9509615e-01],\n",
       "       [3.9083729e-03, 9.9609166e-01],\n",
       "       [2.8881221e-03, 9.9711180e-01],\n",
       "       [1.7733071e-03, 9.9822670e-01],\n",
       "       [1.0424535e-03, 9.9895751e-01],\n",
       "       [5.5245234e-04, 9.9944752e-01],\n",
       "       [3.1591905e-04, 9.9968410e-01],\n",
       "       [1.3631680e-04, 9.9986362e-01],\n",
       "       [4.3392138e-05, 9.9995661e-01],\n",
       "       [1.5405252e-05, 9.9998462e-01],\n",
       "       [8.4139618e-05, 9.9991584e-01],\n",
       "       [3.4838930e-02, 9.6516109e-01]], dtype=float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_player = X_all[np.where(player_ids_all == 'gehrilo01')]\n",
    "lstm.predict(X_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW + KNN\n",
    "\n",
    "Preliminary evaluation of KNN models showed that its accuracy was very poor, so its long evaluation times (due to the large number of samples) made further evaluation not worth the effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn(knn, X_test, y_test):\n",
    "    ones_preds, zeros_preds = None, None\n",
    "    try:\n",
    "        ones_preds = knn.predict([X_test[i] for i in np.where(y_test == 1)[0]])\n",
    "        print(np.sum(ones_preds) / len(ones_preds))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        zeros_preds = knn.predict([X_test[i] for i in np.where(y_test == 0)[0]])\n",
    "        print(np.sum(1-zeros_preds) / len(zeros_preds))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one kNN for all samples by zero-padding samples with less years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_end_career_knn(X_train, y_train, X_test, y_test, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=1, test_zeros_ratio=1, end_careers=True):\n",
    "    \"\"\"\n",
    "    Returns an evaluation of the KNN on only samples representing entire careers of players\n",
    "    \"\"\"\n",
    "    if train_zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_train_0s = np.where(y_train == 0)[0]\n",
    "        idxs_train_1s = np.where(y_train == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_train_0s, size=int(len(idxs_train_0s) * train_zeros_ratio), replace=False)\n",
    "        X_train_ratio_0s = [X_train[i] for i in ratio_0s] + [X_train[i] for i in idxs_train_1s]\n",
    "        y_train_ratio_0s = [y_train[i] for i in ratio_0s] + [y_train[i] for i in idxs_train_1s]\n",
    "    else:\n",
    "        X_train_ratio_0s = X_train\n",
    "        y_train_ratio_0s = y_train\n",
    "\n",
    "    knn_all = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "    knn_all.fit(X_train_ratio_0s, y_train_ratio_0s)\n",
    "    \n",
    "    if end_careers:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] == test_years_played[i]]\n",
    "        display(len(test_idxs_full_careers) / len(X_test))\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio))\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "#         print(idxs_sample_0s)\n",
    "        print(idxs)\n",
    "        eval_knn(knn_all, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        eval_knn(knn_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16960103375868196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1093  246 1129  933  988  148  132 1237 1335 1313  371  265  690  579\n",
      "  778 1562 1925 1144 2063 1061  333 1372 1957  330 1323  752  445  652\n",
      "  557 1128 1446 1513 1372  530  512 1647 1881 1395  911 1356   15   25\n",
      " 1530 1964 1341 1675 1078 1838 1184 1338  159  327  668 1347 1715  254\n",
      " 1407 1249  956 1789 1209  719 1380 1428 1906 1832 1312  476 1835  582\n",
      "  484 1513 1573 1647  739 1133 1099  547 1607  899 1836  993   99  282\n",
      " 1964  917  156 1775  625  504  156  911  893 1793 1927  279 1925 1911\n",
      "  341 1625 1460   20 2005   49   85   92  144  163  185  196  213  225\n",
      "  233  239  259  262  312  451  567  576  580  599  657  673  684  713\n",
      "  716  753  820  833  873  990 1006 1063 1068 1122 1130 1226 1706 1725\n",
      " 2024]\n",
      "0.18421052631578946\n",
      "0.9320388349514563\n"
     ]
    }
   ],
   "source": [
    "eval_end_career_knn(X_train, y_train, X_val, y_val, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=0.25, test_zeros_ratio=0.05, end_careers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one KNN per sample length\n",
    "\n",
    "Train one KNN for each sample length (that is, one KNN each for 1-year samples, 2-year samples, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_year_knn(yr, X_train, y_train, X_test, y_test, idx_train_by_year, idx_test_by_year, zeros_ratio=1):\n",
    "    idxs_train_yr, idxs_test_yr = np.array(idx_train_by_year[yr]), np.array(idx_test_by_year[yr])\n",
    "    \n",
    "    X_train_yr = [X_train_unpad[i] for i in idx_train_by_year[yr]]\n",
    "    y_train_yr = y_train[idx_train_by_year[yr]]\n",
    "    X_test_yr = [X_test_unpad[i] for i in idx_test_by_year[yr]]\n",
    "    y_test_yr = y_test[idx_test_by_year[yr]]\n",
    "    \n",
    "    if zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_yr_train_0s = np.where(y_train_yr == 0)[0]\n",
    "        idxs_yr_train_1s = np.where(y_train_yr == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_yr_train_0s, size=int(len(idxs_yr_train_0s) * zeros_ratio), replace=False)\n",
    "        X_train_yr_ratio_0s = [X_train_yr[i] for i in ratio_0s] + [X_train_yr[i] for i in idxs_yr_train_1s]\n",
    "        y_train_yr_ratio_0s = [y_train_yr[i] for i in ratio_0s] + [y_train_yr[i] for i in idxs_yr_train_1s]\n",
    "    else:\n",
    "        X_train_yr_ratio_0s = X_train_yr\n",
    "        y_train_yr_ratio_0s = y_train_yr\n",
    "    \n",
    "    display(np.where(y_test_yr == 1)[0])\n",
    "    \n",
    "    knn_yr = KNeighborsTimeSeriesClassifier(n_neighbors=1, metric='dtw')\n",
    "    knn_yr.fit(X_train_yr_ratio_0s, y_train_yr_ratio_0s)\n",
    "    \n",
    "    eval_knn(knn_yr, X_test_yr, y_test_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   5,   7,   9,  11,  13,  14,  15,  16,  17,  19,  22,  34,\n",
       "        39,  41,  44,  45,  49,  57,  62,  82,  88,  90,  93,  94, 136,\n",
       "       137, 142, 145, 148, 156, 162, 167])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36363636363636365\n",
      "0.8296296296296296\n"
     ]
    }
   ],
   "source": [
    "eval_year_knn(15, X_train, y_train, X_val, y_val, idx_train_by_year, idx_test_by_year, zeros_ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight={0:0.05, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.05, 1: 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train.reshape((-1, 25*13)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rf.predict_proba(X_test.reshape((-1, 25*13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_outputs/probs_rf_ts.npy', probs[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
