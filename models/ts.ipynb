{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tslearn\n",
    "!pip install pyts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.read_csv('../data_ready/agg/batting_norm_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05280263669863359"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df['hof'].sum() / len(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ab</th>\n",
       "      <th>bb</th>\n",
       "      <th>double</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>hbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>r</th>\n",
       "      <th>rbi</th>\n",
       "      <th>sb</th>\n",
       "      <th>sh</th>\n",
       "      <th>so</th>\n",
       "      <th>triple</th>\n",
       "      <th>years_played</th>\n",
       "      <th>hof</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brownwi02</th>\n",
       "      <td>10592</td>\n",
       "      <td>10920</td>\n",
       "      <td>-0.465167</td>\n",
       "      <td>-0.665236</td>\n",
       "      <td>-0.377410</td>\n",
       "      <td>-0.674567</td>\n",
       "      <td>-0.526152</td>\n",
       "      <td>-0.461885</td>\n",
       "      <td>-0.299984</td>\n",
       "      <td>-0.551212</td>\n",
       "      <td>-0.464428</td>\n",
       "      <td>0.187113</td>\n",
       "      <td>-0.729381</td>\n",
       "      <td>-0.519118</td>\n",
       "      <td>-0.575775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irvinmo01</th>\n",
       "      <td>11421</td>\n",
       "      <td>11788</td>\n",
       "      <td>6.603449</td>\n",
       "      <td>8.807964</td>\n",
       "      <td>4.803380</td>\n",
       "      <td>6.609862</td>\n",
       "      <td>7.416037</td>\n",
       "      <td>9.530594</td>\n",
       "      <td>9.662144</td>\n",
       "      <td>6.773189</td>\n",
       "      <td>10.089170</td>\n",
       "      <td>4.957773</td>\n",
       "      <td>-0.765241</td>\n",
       "      <td>3.414820</td>\n",
       "      <td>8.350465</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hafeych01</th>\n",
       "      <td>3737</td>\n",
       "      <td>3861</td>\n",
       "      <td>12.321097</td>\n",
       "      <td>7.983065</td>\n",
       "      <td>19.091223</td>\n",
       "      <td>11.529930</td>\n",
       "      <td>13.803409</td>\n",
       "      <td>14.668519</td>\n",
       "      <td>23.235878</td>\n",
       "      <td>13.903553</td>\n",
       "      <td>17.199094</td>\n",
       "      <td>8.695445</td>\n",
       "      <td>4.445297</td>\n",
       "      <td>17.597934</td>\n",
       "      <td>10.686704</td>\n",
       "      <td>13.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camparo01</th>\n",
       "      <td>11012</td>\n",
       "      <td>11346</td>\n",
       "      <td>14.153932</td>\n",
       "      <td>15.011866</td>\n",
       "      <td>12.308864</td>\n",
       "      <td>13.736424</td>\n",
       "      <td>14.082515</td>\n",
       "      <td>12.369475</td>\n",
       "      <td>29.090691</td>\n",
       "      <td>14.581532</td>\n",
       "      <td>23.779343</td>\n",
       "      <td>3.670171</td>\n",
       "      <td>2.375898</td>\n",
       "      <td>15.080184</td>\n",
       "      <td>2.371652</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilsoha01</th>\n",
       "      <td>3601</td>\n",
       "      <td>3725</td>\n",
       "      <td>13.881088</td>\n",
       "      <td>22.589546</td>\n",
       "      <td>13.935954</td>\n",
       "      <td>13.908143</td>\n",
       "      <td>14.449937</td>\n",
       "      <td>6.813193</td>\n",
       "      <td>38.749986</td>\n",
       "      <td>18.008864</td>\n",
       "      <td>25.228414</td>\n",
       "      <td>5.245698</td>\n",
       "      <td>7.282968</td>\n",
       "      <td>34.855209</td>\n",
       "      <td>11.491814</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ripkeca01</th>\n",
       "      <td>25987</td>\n",
       "      <td>26480</td>\n",
       "      <td>40.925585</td>\n",
       "      <td>34.059953</td>\n",
       "      <td>40.960233</td>\n",
       "      <td>37.979274</td>\n",
       "      <td>40.824505</td>\n",
       "      <td>18.550806</td>\n",
       "      <td>43.485983</td>\n",
       "      <td>40.166549</td>\n",
       "      <td>43.555044</td>\n",
       "      <td>-0.432205</td>\n",
       "      <td>-0.688196</td>\n",
       "      <td>21.101473</td>\n",
       "      <td>12.226009</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murraed02</th>\n",
       "      <td>23975</td>\n",
       "      <td>24468</td>\n",
       "      <td>39.150338</td>\n",
       "      <td>43.185970</td>\n",
       "      <td>38.235980</td>\n",
       "      <td>38.546247</td>\n",
       "      <td>41.621386</td>\n",
       "      <td>3.937850</td>\n",
       "      <td>57.153712</td>\n",
       "      <td>40.600355</td>\n",
       "      <td>53.298252</td>\n",
       "      <td>3.559524</td>\n",
       "      <td>-0.680393</td>\n",
       "      <td>29.500643</td>\n",
       "      <td>5.989076</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yastrca01</th>\n",
       "      <td>15796</td>\n",
       "      <td>16271</td>\n",
       "      <td>41.835125</td>\n",
       "      <td>67.892039</td>\n",
       "      <td>53.900083</td>\n",
       "      <td>39.887946</td>\n",
       "      <td>45.061597</td>\n",
       "      <td>8.871536</td>\n",
       "      <td>51.765388</td>\n",
       "      <td>49.597076</td>\n",
       "      <td>53.654928</td>\n",
       "      <td>19.230504</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>27.049242</td>\n",
       "      <td>16.240953</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaronha01</th>\n",
       "      <td>12889</td>\n",
       "      <td>13339</td>\n",
       "      <td>46.029512</td>\n",
       "      <td>48.546825</td>\n",
       "      <td>55.022065</td>\n",
       "      <td>40.023800</td>\n",
       "      <td>53.887018</td>\n",
       "      <td>6.797289</td>\n",
       "      <td>93.228241</td>\n",
       "      <td>63.981689</td>\n",
       "      <td>72.061626</td>\n",
       "      <td>39.286922</td>\n",
       "      <td>3.638755</td>\n",
       "      <td>29.936938</td>\n",
       "      <td>33.967563</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosepe01</th>\n",
       "      <td>16854</td>\n",
       "      <td>17329</td>\n",
       "      <td>51.081092</td>\n",
       "      <td>53.260293</td>\n",
       "      <td>62.637534</td>\n",
       "      <td>43.964491</td>\n",
       "      <td>59.567020</td>\n",
       "      <td>43.876384</td>\n",
       "      <td>12.992789</td>\n",
       "      <td>62.411365</td>\n",
       "      <td>32.445848</td>\n",
       "      <td>18.102442</td>\n",
       "      <td>5.441395</td>\n",
       "      <td>16.720960</td>\n",
       "      <td>52.376027</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  Unnamed: 0.1         ab         bb     double  \\\n",
       "player_id                                                              \n",
       "brownwi02       10592         10920  -0.465167  -0.665236  -0.377410   \n",
       "irvinmo01       11421         11788   6.603449   8.807964   4.803380   \n",
       "hafeych01        3737          3861  12.321097   7.983065  19.091223   \n",
       "camparo01       11012         11346  14.153932  15.011866  12.308864   \n",
       "wilsoha01        3601          3725  13.881088  22.589546  13.935954   \n",
       "...               ...           ...        ...        ...        ...   \n",
       "ripkeca01       25987         26480  40.925585  34.059953  40.960233   \n",
       "murraed02       23975         24468  39.150338  43.185970  38.235980   \n",
       "yastrca01       15796         16271  41.835125  67.892039  53.900083   \n",
       "aaronha01       12889         13339  46.029512  48.546825  55.022065   \n",
       "rosepe01        16854         17329  51.081092  53.260293  62.637534   \n",
       "\n",
       "                   g          h        hbp         hr          r        rbi  \\\n",
       "player_id                                                                     \n",
       "brownwi02  -0.674567  -0.526152  -0.461885  -0.299984  -0.551212  -0.464428   \n",
       "irvinmo01   6.609862   7.416037   9.530594   9.662144   6.773189  10.089170   \n",
       "hafeych01  11.529930  13.803409  14.668519  23.235878  13.903553  17.199094   \n",
       "camparo01  13.736424  14.082515  12.369475  29.090691  14.581532  23.779343   \n",
       "wilsoha01  13.908143  14.449937   6.813193  38.749986  18.008864  25.228414   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "ripkeca01  37.979274  40.824505  18.550806  43.485983  40.166549  43.555044   \n",
       "murraed02  38.546247  41.621386   3.937850  57.153712  40.600355  53.298252   \n",
       "yastrca01  39.887946  45.061597   8.871536  51.765388  49.597076  53.654928   \n",
       "aaronha01  40.023800  53.887018   6.797289  93.228241  63.981689  72.061626   \n",
       "rosepe01   43.964491  59.567020  43.876384  12.992789  62.411365  32.445848   \n",
       "\n",
       "                  sb        sh         so     triple  years_played   hof  \n",
       "player_id                                                                 \n",
       "brownwi02   0.187113 -0.729381  -0.519118  -0.575775           1.0  True  \n",
       "irvinmo01   4.957773 -0.765241   3.414820   8.350465           8.0  True  \n",
       "hafeych01   8.695445  4.445297  17.597934  10.686704          13.0  True  \n",
       "camparo01   3.670171  2.375898  15.080184   2.371652          10.0  True  \n",
       "wilsoha01   5.245698  7.282968  34.855209  11.491814          12.0  True  \n",
       "...              ...       ...        ...        ...           ...   ...  \n",
       "ripkeca01  -0.432205 -0.688196  21.101473  12.226009          21.0  True  \n",
       "murraed02   3.559524 -0.680393  29.500643   5.989076          21.0  True  \n",
       "yastrca01  19.230504 -0.015463  27.049242  16.240953          23.0  True  \n",
       "aaronha01  39.286922  3.638755  29.936938  33.967563          23.0  True  \n",
       "rosepe01   18.102442  5.441395  16.720960  52.376027          24.0  True  \n",
       "\n",
       "[130 rows x 17 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg2[agg2['hof']].sort_values('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9cb87f0c10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg2 = agg_df.groupby('player_id').max('years_played')\n",
    "agg2.plot.scatter('g', 'h', c=['red' if agg2.iloc[i]['hof'] else 'blue' for i in range(len(agg2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>bb</th>\n",
       "      <th>double</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>hbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>player_id</th>\n",
       "      <th>r</th>\n",
       "      <th>rbi</th>\n",
       "      <th>sb</th>\n",
       "      <th>sh</th>\n",
       "      <th>so</th>\n",
       "      <th>triple</th>\n",
       "      <th>years_played</th>\n",
       "      <th>hof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.661588</td>\n",
       "      <td>-0.438871</td>\n",
       "      <td>-0.640879</td>\n",
       "      <td>-0.705525</td>\n",
       "      <td>-0.583966</td>\n",
       "      <td>-0.539028</td>\n",
       "      <td>-0.388342</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.539369</td>\n",
       "      <td>-0.609924</td>\n",
       "      <td>-0.335788</td>\n",
       "      <td>-0.665060</td>\n",
       "      <td>-0.794309</td>\n",
       "      <td>-0.310270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.145500</td>\n",
       "      <td>-0.634319</td>\n",
       "      <td>-1.124076</td>\n",
       "      <td>-1.026475</td>\n",
       "      <td>-1.017650</td>\n",
       "      <td>-1.125153</td>\n",
       "      <td>-0.813317</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.903027</td>\n",
       "      <td>-1.153566</td>\n",
       "      <td>-0.636014</td>\n",
       "      <td>-1.424980</td>\n",
       "      <td>-0.892177</td>\n",
       "      <td>-0.404662</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.161406</td>\n",
       "      <td>-0.031041</td>\n",
       "      <td>-1.378979</td>\n",
       "      <td>-0.693510</td>\n",
       "      <td>-1.160762</td>\n",
       "      <td>-0.056680</td>\n",
       "      <td>-1.235447</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.879855</td>\n",
       "      <td>-1.079926</td>\n",
       "      <td>-0.389503</td>\n",
       "      <td>-1.058649</td>\n",
       "      <td>-1.112142</td>\n",
       "      <td>-0.762685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.954610</td>\n",
       "      <td>-0.615781</td>\n",
       "      <td>-2.052017</td>\n",
       "      <td>-1.647343</td>\n",
       "      <td>-1.893377</td>\n",
       "      <td>-0.604941</td>\n",
       "      <td>-1.638442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.575987</td>\n",
       "      <td>-1.775687</td>\n",
       "      <td>-0.956969</td>\n",
       "      <td>-1.764229</td>\n",
       "      <td>-2.108656</td>\n",
       "      <td>-1.364642</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.744661</td>\n",
       "      <td>-0.229190</td>\n",
       "      <td>-2.314481</td>\n",
       "      <td>-1.438181</td>\n",
       "      <td>-1.531243</td>\n",
       "      <td>-1.148788</td>\n",
       "      <td>-2.011442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.190280</td>\n",
       "      <td>-1.700775</td>\n",
       "      <td>-0.966303</td>\n",
       "      <td>-1.027140</td>\n",
       "      <td>-2.202136</td>\n",
       "      <td>-0.952990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43686</th>\n",
       "      <td>-0.448198</td>\n",
       "      <td>-0.350041</td>\n",
       "      <td>-0.506754</td>\n",
       "      <td>-0.542378</td>\n",
       "      <td>-0.443520</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>turnetr01</td>\n",
       "      <td>-0.407728</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.390894</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43687</th>\n",
       "      <td>0.781068</td>\n",
       "      <td>0.410928</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.614127</td>\n",
       "      <td>0.573732</td>\n",
       "      <td>0.309030</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>urshegi01</td>\n",
       "      <td>0.382690</td>\n",
       "      <td>0.258928</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>0.058954</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43688</th>\n",
       "      <td>-0.659393</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-1.099213</td>\n",
       "      <td>-0.623035</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>waldrky02</td>\n",
       "      <td>-0.605333</td>\n",
       "      <td>-0.587657</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.663400</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43689</th>\n",
       "      <td>-0.551088</td>\n",
       "      <td>-0.513105</td>\n",
       "      <td>-0.308580</td>\n",
       "      <td>-0.949296</td>\n",
       "      <td>-0.503358</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>willima07</td>\n",
       "      <td>-0.486770</td>\n",
       "      <td>-0.466716</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.613853</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43690</th>\n",
       "      <td>-0.491520</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-0.906462</td>\n",
       "      <td>-0.483412</td>\n",
       "      <td>-0.071749</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>willima08</td>\n",
       "      <td>-0.526291</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.489987</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43691 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ab        bb    double         g         h       hbp        hr  \\\n",
       "0     -0.661588 -0.438871 -0.640879 -0.705525 -0.583966 -0.539028 -0.388342   \n",
       "1     -1.145500 -0.634319 -1.124076 -1.026475 -1.017650 -1.125153 -0.813317   \n",
       "2     -1.161406 -0.031041 -1.378979 -0.693510 -1.160762 -0.056680 -1.235447   \n",
       "3     -1.954610 -0.615781 -2.052017 -1.647343 -1.893377 -0.604941 -1.638442   \n",
       "4     -1.744661 -0.229190 -2.314481 -1.438181 -1.531243 -1.148788 -2.011442   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "43686 -0.448198 -0.350041 -0.506754 -0.542378 -0.443520 -0.452528 -0.364299   \n",
       "43687  0.781068  0.410928  0.186854  0.614127  0.573732  0.309030  0.325219   \n",
       "43688 -0.659393 -0.567460 -0.605841 -1.099213 -0.623035 -0.452528 -0.502202   \n",
       "43689 -0.551088 -0.513105 -0.308580 -0.949296 -0.503358 -0.452528 -0.364299   \n",
       "43690 -0.491520 -0.567460 -0.605841 -0.906462 -0.483412 -0.071749 -0.502202   \n",
       "\n",
       "       player_id         r       rbi        sb        sh        so    triple  \\\n",
       "0      acostme01 -0.539369 -0.609924 -0.335788 -0.665060 -0.794309 -0.310270   \n",
       "1      acostme01 -0.903027 -1.153566 -0.636014 -1.424980 -0.892177 -0.404662   \n",
       "2      acostme01 -0.879855 -1.079926 -0.389503 -1.058649 -1.112142 -0.762685   \n",
       "3      acostme01 -1.575987 -1.775687 -0.956969 -1.764229 -2.108656 -1.364642   \n",
       "4      acostme01 -1.190280 -1.700775 -0.966303 -1.027140 -2.202136 -0.952990   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "43686  turnetr01 -0.407728 -0.547344  0.027295 -0.478008 -0.390894 -0.427949   \n",
       "43687  urshegi01  0.382690  0.258928 -0.357982  0.058954  0.748672  0.186402   \n",
       "43688  waldrky02 -0.605333 -0.587657 -0.357982 -0.478008 -0.663400 -0.427949   \n",
       "43689  willima07 -0.486770 -0.466716 -0.357982 -0.478008 -0.613853 -0.427949   \n",
       "43690  willima08 -0.526291 -0.547344 -0.357982 -0.478008 -0.489987  0.186402   \n",
       "\n",
       "       years_played    hof  \n",
       "0               1.0  False  \n",
       "1               2.0  False  \n",
       "2               3.0  False  \n",
       "3               4.0  False  \n",
       "4               5.0  False  \n",
       "...             ...    ...  \n",
       "43686           1.0  False  \n",
       "43687           1.0  False  \n",
       "43688           1.0  False  \n",
       "43689           1.0  False  \n",
       "43690           1.0  False  \n",
       "\n",
       "[43691 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_length = agg_df.groupby('player_id')['years_played'].max()\n",
    "players_5yrs = career_length[career_length > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the time series samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches:\n",
    "* Zero pad, and throw into one time series classifier  \n",
    "* Train one time series classifier for each length (1-year careers, 2-year careers, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load('../data_ready/ts/X_all.npy')\n",
    "y_all = np.load('../data_ready/y_all.npy')\n",
    "years_played_all = np.load('../data_ready/years_played_all.npy')\n",
    "player_ids_all = np.load('../data_ready/player_ids_all.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test split by HOF / non-hof players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_players = agg_df[agg_df['hof']]['player_id'].unique()\n",
    "non_hof_players = agg_df[~agg_df['hof']]['player_id'].unique()\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(hof_players), np.random.shuffle(non_hof_players);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "zeros_ratio = 1\n",
    "n_hof, n_non = len(hof_players), len(non_hof_players)\n",
    "\n",
    "train_hof, test_hof = hof_players[:int(n_hof*train_ratio)], hof_players[int(n_hof*train_ratio):]\n",
    "train_non, test_non = non_hof_players[:int(n_non*train_ratio)], non_hof_players[int(n_non*train_ratio):]\n",
    "\n",
    "train_non_sample = train_non[:int(len(train_non)*zeros_ratio)]\n",
    "\n",
    "train_players, test_players = set(np.concatenate((train_hof, train_non_sample))), set(np.concatenate((test_hof, test_non)))\n",
    "train_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in train_players])\n",
    "test_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in test_players])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brownwi02', 'gehrich01', 'snidedu01', 'camparo01', 'sislege01',\n",
       "       'guerrvl01', 'gosligo01', 'perezto01', 'riceji01', 'winfida01',\n",
       "       'smithoz01', 'benchjo01', 'bankser01', 'martied01', 'bottoji01',\n",
       "       'lazzeto01', 'cronijo01', 'ripkeca01', 'traynpi01', 'morgajo02',\n",
       "       'manushe01', 'molitpa01', 'wilsoha01', 'reesepe01', 'simmoal01',\n",
       "       'ricesa01', 'gwynnto01', 'killeha01', 'robinfr02', 'heilmha01',\n",
       "       'jackstr01', 'irvinmo01', 'willibi01', 'kellyge01', 'mazerbi01',\n",
       "       'friscfr01', 'beltrad01', 'clemero01', 'applilu01'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_all[train_idxs], X_all[test_idxs]\n",
    "y_train, y_test = y_all[train_idxs], y_all[test_idxs]\n",
    "train_years_played, test_years_played = years_played_all[train_idxs], years_played_all[test_idxs]\n",
    "train_player_ids, test_player_ids = player_ids_all[train_idxs], player_ids_all[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undo zero-padding + group idxs by # of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unpad, X_test_unpad = [], []\n",
    "idx_train_by_year, idx_test_by_year = [[] for _ in range(26)], [[] for _ in range(26)]\n",
    "for i in range(X_train.shape[0]):\n",
    "    yrs_played = int(train_years_played[i])\n",
    "    idx_train_by_year[yrs_played].append(i)\n",
    "    X_train_unpad.append(X_train[i][:yrs_played])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yrs_played = int(test_years_played[i])\n",
    "    idx_test_by_year[yrs_played].append(i)\n",
    "    X_test_unpad.append(X_test[i][:yrs_played])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of HOFers + # of samples for each career length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04365079365079365, 2016),\n",
       " (0.05648267008985879, 1558),\n",
       " (0.0682699767261443, 1289),\n",
       " (0.08014571948998178, 1098),\n",
       " (0.09292502639915523, 947),\n",
       " (0.10438908659549229, 843),\n",
       " (0.11780455153949129, 747),\n",
       " (0.13273001508295626, 663),\n",
       " (0.1543859649122807, 570),\n",
       " (0.1825726141078838, 482),\n",
       " (0.2119700748129676, 401),\n",
       " (0.24561403508771928, 342),\n",
       " (0.31297709923664124, 262),\n",
       " (0.34101382488479265, 217),\n",
       " (0.39325842696629215, 178),\n",
       " (0.4701492537313433, 134),\n",
       " (0.5263157894736842, 114),\n",
       " (0.6710526315789473, 76),\n",
       " (0.7543859649122807, 57),\n",
       " (0.9166666666666666, 36),\n",
       " (0.9615384615384616, 26),\n",
       " (1.0, 18),\n",
       " (1.0, 8),\n",
       " (1.0, 3),\n",
       " (1.0, 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-170-ff41d8fec79c>:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.018095238095238095, 2100),\n",
       " (0.023125, 1600),\n",
       " (0.028136882129277566, 1315),\n",
       " (0.03268551236749117, 1132),\n",
       " (0.03707414829659319, 998),\n",
       " (0.041666666666666664, 888),\n",
       " (0.04798962386511025, 771),\n",
       " (0.0549777117384844, 673),\n",
       " (0.060810810810810814, 592),\n",
       " (0.0728744939271255, 494),\n",
       " (0.08333333333333333, 420),\n",
       " (0.10174418604651163, 344),\n",
       " (0.12546125461254612, 271),\n",
       " (0.1588785046728972, 214),\n",
       " (0.19642857142857142, 168),\n",
       " (0.22962962962962963, 135),\n",
       " (0.25742574257425743, 101),\n",
       " (0.30434782608695654, 69),\n",
       " (0.37209302325581395, 43),\n",
       " (0.4444444444444444, 27),\n",
       " (0.5384615384615384, 13),\n",
       " (0.4, 10),\n",
       " (0.3333333333333333, 3),\n",
       " (0.0, 1),\n",
       " (nan, 0)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training data')\n",
    "train_hist = [(np.sum(y_train[idx_train_by_year[i]]) / len(idx_train_by_year[i]), len(idx_train_by_year[i])) for i in range(1, 26)]\n",
    "display(train_hist)\n",
    "print('test data')\n",
    "test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n",
    "test_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random HOF and non-HOF samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "hof_rand, non_hof_rand = np.random.choice(np.where(y_train == 1)[0]), np.random.choice(np.where(y_train == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1397146 ,  2.02168166,  1.67783737,  1.08165126,  0.79330746,\n",
       "         0.4307195 ,  1.43247401,  1.64431773,  0.89903381,  3.21099742,\n",
       "         0.01175137,  2.02244887,  0.97868075],\n",
       "       [ 1.83910241,  1.49446174,  2.36819163,  1.85646077,  1.6838071 ,\n",
       "         0.92022933,  2.13481438,  2.35548097,  1.15177433,  2.77268543,\n",
       "        -0.66056693,  1.58710637,  3.81924303]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bondsba01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.74951754, -0.66633881, -0.60523593, -0.95311561, -0.67348963,\n",
       "        -0.56572792, -0.42212953, -0.69881213, -0.68285082, -0.57575304,\n",
       "        -0.75457976, -1.0194754 , -0.35802334]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'kolseka01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in (hof_rand, non_hof_rand):\n",
    "    display(X_train_unpad[i], train_years_played[i], train_player_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCKET \n",
    "hinge: train in 70 sec, 90 epochs  \n",
    "log: train in 150 sec, 101 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Trying 70/30 splits because 80/20 gives too few 'full career' test samples of HOFers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sktime.transformers.series_as_features.rocket import Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket(rocket_pipeline, X_test, y_test):\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "#         print('ones ({})'.format(np.sum(y_test)))\n",
    "        ones_preds = rocket_pipeline.predict(X_test[y_test == 1])\n",
    "        ones_score = np.sum(ones_preds) / len(ones_preds)\n",
    "#         print(ones_score)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "#         print('zeros ({})'.format(np.sum(1-y_test)))\n",
    "        zeros_preds = rocket_pipeline.predict(X_test[y_test == 0])\n",
    "        zeros_score = np.sum(1-zeros_preds) / len(zeros_preds)\n",
    "#         print(zeros_score)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket_by_year(rocket_pipeline, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "    \n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "        if years_before_end == 0:\n",
    "            print(classification_report(y_test_full_careers[idxs], rocket_pipeline.predict(X_test_full_careers[idxs])))\n",
    "            print(percent_fp_got_votes(y_test_full_careers[idxs], rocket_pipeline.predict(X_test_full_careers[idxs]), test_player_ids[test_idxs_full_careers][idxs]))\n",
    "        \n",
    "        return eval_rocket(rocket_pipeline, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_rocket(rocket_pipeline, X_test, y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_sgd = make_pipeline(Rocket(), SGDClassifier(eta0=0.001, learning_rate='adaptive', verbose=1, class_weight={0:0.01, 1:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96      2062\n",
      "           1       0.10      0.45      0.16        38\n",
      "\n",
      "    accuracy                           0.92      2100\n",
      "   macro avg       0.54      0.69      0.56      2100\n",
      "weighted avg       0.97      0.92      0.94      2100\n",
      "\n",
      "0.05806451612903226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.4473684210526316, 38), (0.9248302618816683, 2062))"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=0)\n",
    "ones_score, zeros_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96      2062\n",
      "           1       0.10      0.45      0.16        38\n",
      "\n",
      "    accuracy                           0.92      2100\n",
      "   macro avg       0.54      0.69      0.56      2100\n",
      "weighted avg       0.97      0.92      0.94      2100\n",
      "\n",
      "0.05806451612903226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0.4473684210526316, 38),\n",
       "  (0.3783783783783784, 37),\n",
       "  (0.32432432432432434, 37),\n",
       "  (0.32432432432432434, 37),\n",
       "  (0.32432432432432434, 37),\n",
       "  (0.2972972972972973, 37),\n",
       "  (0.1891891891891892, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.19444444444444445, 36),\n",
       "  (0.1111111111111111, 36),\n",
       "  (0.11428571428571428, 35),\n",
       "  (0.11428571428571428, 35),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.14705882352941177, 34),\n",
       "  (0.15151515151515152, 33),\n",
       "  (0.06451612903225806, 31),\n",
       "  (0.07692307692307693, 26),\n",
       "  (0.19047619047619047, 21),\n",
       "  (0.1875, 16),\n",
       "  (0.08333333333333333, 12),\n",
       "  (0.42857142857142855, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9248302618816683, 2062),\n",
       "  (0.9520153550863724, 1563),\n",
       "  (0.9491392801251957, 1278),\n",
       "  (0.9452054794520548, 1095),\n",
       "  (0.9531737773152965, 961),\n",
       "  (0.9435957696827262, 851),\n",
       "  (0.9564032697547684, 734),\n",
       "  (0.940251572327044, 636),\n",
       "  (0.935251798561151, 556),\n",
       "  (0.9192139737991266, 458),\n",
       "  (0.9246753246753247, 385),\n",
       "  (0.9061488673139159, 309),\n",
       "  (0.890295358649789, 237),\n",
       "  (0.9111111111111111, 180),\n",
       "  (0.9407407407407408, 135),\n",
       "  (0.8846153846153846, 104),\n",
       "  (0.84, 75),\n",
       "  (0.8125, 48),\n",
       "  (0.8518518518518519, 27),\n",
       "  (0.9333333333333333, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_preds, zeros_preds, ones_scores, zeros_scores = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores.append(ones_score), zeros_scores.append(zeros_score)\n",
    "    ones_preds.append(ones_pred), zeros_preds.append(zeros_pred)\n",
    "ones_scores, zeros_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-920fad30d491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mones_preds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-315-920fad30d491>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mones_preds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     28\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     29\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "[x.max(axis=1).mean(axis=0) for x in ones_preds if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_lr = make_pipeline(Rocket(), LogisticRegression(verbose=1, class_weight={0:0.1, 1:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/nick/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rocket', Rocket()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight={0: 0.01, 1: 1}, verbose=1))])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocket_pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94      2062\n",
      "           1       0.06      0.32      0.10        38\n",
      "\n",
      "    accuracy                           0.90      2100\n",
      "   macro avg       0.52      0.61      0.52      2100\n",
      "weighted avg       0.97      0.90      0.93      2100\n",
      "\n",
      "0.061855670103092786\n"
     ]
    }
   ],
   "source": [
    "ones_preds_lr, zeros_preds_lr, ones_scores_lr, zeros_scores_lr = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_lr, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores_lr.append(ones_score), zeros_scores_lr.append(zeros_score)\n",
    "    ones_preds_lr.append(ones_pred), zeros_preds_lr.append(zeros_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.max(axis=1).mean(axis=0) for x in ones_preds_lr if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.3157894736842105, 38),\n",
       "  (0.24324324324324326, 37),\n",
       "  (0.2702702702702703, 37),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.1891891891891892, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.10810810810810811, 37),\n",
       "  (0.1891891891891892, 37),\n",
       "  (0.19444444444444445, 36),\n",
       "  (0.16666666666666666, 36),\n",
       "  (0.17142857142857143, 35),\n",
       "  (0.17142857142857143, 35),\n",
       "  (0.14705882352941177, 34),\n",
       "  (0.11764705882352941, 34),\n",
       "  (0.24242424242424243, 33),\n",
       "  (0.12903225806451613, 31),\n",
       "  (0.15384615384615385, 26),\n",
       "  (0.19047619047619047, 21),\n",
       "  (0.1875, 16),\n",
       "  (0.25, 12),\n",
       "  (0.2857142857142857, 7),\n",
       "  (0.25, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9059165858389913, 2062),\n",
       "  (0.9315419065898912, 1563),\n",
       "  (0.9280125195618153, 1278),\n",
       "  (0.9324200913242009, 1095),\n",
       "  (0.9406867845993756, 961),\n",
       "  (0.918918918918919, 851),\n",
       "  (0.9182561307901907, 734),\n",
       "  (0.9025157232704403, 636),\n",
       "  (0.9046762589928058, 556),\n",
       "  (0.8799126637554585, 458),\n",
       "  (0.8727272727272727, 385),\n",
       "  (0.8576051779935275, 309),\n",
       "  (0.869198312236287, 237),\n",
       "  (0.8888888888888888, 180),\n",
       "  (0.8814814814814815, 135),\n",
       "  (0.8653846153846154, 104),\n",
       "  (0.7733333333333333, 75),\n",
       "  (0.7708333333333334, 48),\n",
       "  (0.8148148148148148, 27),\n",
       "  (1.0, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores_lr, zeros_scores_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "#### best settings: all 0s, class weight 0.05, 50 epochs, LSTM 20, Dense 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainX, trainy):\n",
    "    verbose, epochs, batch_size = 1, 50, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=(n_timesteps,n_features)))\n",
    "#     model.add(LSTM(100))    , return_sequences=True\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose, class_weight={0:0.05, 1:1.0})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm(lstm, X_test, y_test):\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "#         print('ones ({})'.format(np.sum(y_test)))\n",
    "        ones_preds = lstm.predict(X_test[y_test == 1], batch_size=64, verbose=0)\n",
    "\n",
    "        ones_score = np.sum(np.argmax(ones_preds, axis=1)) / len(ones_preds)\n",
    "#         print(ones_score)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "#         print('zeros ({})'.format(np.sum(1-y_test)))\n",
    "        zeros_preds = lstm.predict(X_test[y_test == 0], batch_size=64, verbose=0)\n",
    "        zeros_score = np.sum(1-np.argmax(zeros_preds, axis=1)) / len(zeros_preds)\n",
    "#         print(zeros_score)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "    \n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "        if years_before_end == 0:\n",
    "            print(classification_report(y_test_full_careers[idxs], np.argmax(lstm.predict(X_test_full_careers[idxs]), axis=1)))\n",
    "            print(percent_fp_got_votes(y_test_full_careers[idxs], np.argmax(lstm.predict(X_test_full_careers[idxs]), axis=1), test_player_ids[test_idxs_full_careers][idxs]))\n",
    "        return eval_lstm(lstm, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_rocket(lstm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05647294302666381"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9459459459459459, 37), (0.889955214331414, 1563))"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_lstm_by_year(good_lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=1)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0306 - accuracy: 0.6612\n",
      "Epoch 2/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0244 - accuracy: 0.7547\n",
      "Epoch 3/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0225 - accuracy: 0.7888\n",
      "Epoch 4/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0211 - accuracy: 0.7949\n",
      "Epoch 5/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0204 - accuracy: 0.8088\n",
      "Epoch 6/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0200 - accuracy: 0.8177\n",
      "Epoch 7/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0190 - accuracy: 0.8233\n",
      "Epoch 8/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.8415\n",
      "Epoch 9/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0176 - accuracy: 0.8459\n",
      "Epoch 10/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0176 - accuracy: 0.8518\n",
      "Epoch 11/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0171 - accuracy: 0.8570\n",
      "Epoch 12/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0172 - accuracy: 0.8576\n",
      "Epoch 13/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0161 - accuracy: 0.8685\n",
      "Epoch 14/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0159 - accuracy: 0.8732\n",
      "Epoch 15/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.8595\n",
      "Epoch 16/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0188 - accuracy: 0.8379\n",
      "Epoch 17/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0153 - accuracy: 0.8792\n",
      "Epoch 18/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0152 - accuracy: 0.8800\n",
      "Epoch 19/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.8982\n",
      "Epoch 20/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.8973\n",
      "Epoch 21/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0157 - accuracy: 0.8810\n",
      "Epoch 22/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0144 - accuracy: 0.8957\n",
      "Epoch 23/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0151 - accuracy: 0.8870\n",
      "Epoch 24/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9019\n",
      "Epoch 25/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9108\n",
      "Epoch 26/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9052\n",
      "Epoch 27/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0139 - accuracy: 0.9008\n",
      "Epoch 28/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9149\n",
      "Epoch 30/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9075\n",
      "Epoch 31/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.8927\n",
      "Epoch 32/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9173\n",
      "Epoch 33/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0147 - accuracy: 0.8805\n",
      "Epoch 34/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0129 - accuracy: 0.9065\n",
      "Epoch 35/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0130 - accuracy: 0.9107\n",
      "Epoch 36/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0130 - accuracy: 0.9094\n",
      "Epoch 37/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9114\n",
      "Epoch 38/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9138\n",
      "Epoch 39/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0118 - accuracy: 0.9180\n",
      "Epoch 40/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9149\n",
      "Epoch 41/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.8962\n",
      "Epoch 42/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9137\n",
      "Epoch 43/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9151\n",
      "Epoch 44/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9076\n",
      "Epoch 45/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9219\n",
      "Epoch 46/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9352\n",
      "Epoch 47/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9328\n",
      "Epoch 48/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9344\n",
      "Epoch 49/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9251\n",
      "Epoch 50/50\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "lstm = train_model(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      2138\n",
      "           1       0.29      0.72      0.42       144\n",
      "\n",
      "    accuracy                           0.87      2282\n",
      "   macro avg       0.64      0.80      0.67      2282\n",
      "weighted avg       0.94      0.87      0.90      2282\n",
      "\n",
      "0.13545816733067728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7222222222222222, 144), (0.882600561272217, 2138))"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, o, z = eval_lstm_by_year(lstm, X_test, y_test, agg_df, train_player_ids, train_years_played, years_before_end=0)\n",
    "o, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = load_model('better_lstm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_fp_got_votes(y_true, y_preds, idx_player_ids): # about half\n",
    "    fp_idxs = np.where((y_true == 0) & (y_preds == 1))[0]\n",
    "    fp_players = idx_player_ids[fp_idxs]\n",
    "    hof = pd.read_csv('../data_normalized/hall_of_fame.csv')\n",
    "    return np.mean(np.isin(fp_players, hof['player_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      2062\n",
      "           1       0.27      0.79      0.41        38\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.63      0.88      0.69      2100\n",
      "weighted avg       0.98      0.96      0.97      2100\n",
      "\n",
      "0.475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0.7894736842105263, 38),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8108108108108109, 37),\n",
       "  (0.8108108108108109, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8648648648648649, 37),\n",
       "  (0.7567567567567568, 37),\n",
       "  (0.75, 36),\n",
       "  (0.7222222222222222, 36),\n",
       "  (0.7428571428571429, 35),\n",
       "  (0.6857142857142857, 35),\n",
       "  (0.6470588235294118, 34),\n",
       "  (0.7352941176470589, 34),\n",
       "  (0.6060606060606061, 33),\n",
       "  (0.5806451612903226, 31),\n",
       "  (0.4230769230769231, 26),\n",
       "  (0.47619047619047616, 21),\n",
       "  (0.5, 16),\n",
       "  (0.5, 12),\n",
       "  (0.2857142857142857, 7),\n",
       "  (0.25, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9612027158098934, 2062),\n",
       "  (0.9321817018554063, 1563),\n",
       "  (0.9100156494522692, 1278),\n",
       "  (0.8849315068493151, 1095),\n",
       "  (0.8626430801248699, 961),\n",
       "  (0.8401880141010576, 851),\n",
       "  (0.8501362397820164, 734),\n",
       "  (0.8380503144654088, 636),\n",
       "  (0.8165467625899281, 556),\n",
       "  (0.8013100436681223, 458),\n",
       "  (0.787012987012987, 385),\n",
       "  (0.7928802588996764, 309),\n",
       "  (0.7890295358649789, 237),\n",
       "  (0.8111111111111111, 180),\n",
       "  (0.7851851851851852, 135),\n",
       "  (0.7788461538461539, 104),\n",
       "  (0.84, 75),\n",
       "  (0.8333333333333334, 48),\n",
       "  (0.8518518518518519, 27),\n",
       "  (0.9333333333333333, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (0.5, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_preds_lstm, zeros_preds_lstm, ones_scores_lstm, zeros_scores_lstm = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores_lstm.append(ones_score), zeros_scores_lstm.append(zeros_score)\n",
    "    ones_preds_lstm.append(ones_pred), zeros_preds_lstm.append(zeros_pred)\n",
    "ones_scores_lstm, zeros_scores_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.96      0.98      2062\n",
    "               1       0.27      0.79      0.41        38\n",
    "\n",
    "        accuracy                           0.96      2100\n",
    "       macro avg       0.63      0.88      0.69      2100\n",
    "    weighted avg       0.98      0.96      0.97      2100\n",
    "good_lstm ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.93      0.97      2062\n",
    "               1       0.20      0.92      0.33        38\n",
    "\n",
    "        accuracy                           0.93      2100\n",
    "       macro avg       0.60      0.93      0.65      2100\n",
    "    weighted avg       0.98      0.93      0.95      2100\n",
    "    \n",
    "better_lstm ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.9210526315789473, 38),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.9459459459459459, 37),\n",
       "  (0.8918918918918919, 37),\n",
       "  (0.918918918918919, 37),\n",
       "  (0.8378378378378378, 37),\n",
       "  (0.8333333333333334, 36),\n",
       "  (0.8055555555555556, 36),\n",
       "  (0.8, 35),\n",
       "  (0.7428571428571429, 35),\n",
       "  (0.7058823529411765, 34),\n",
       "  (0.7352941176470589, 34),\n",
       "  (0.5454545454545454, 33),\n",
       "  (0.5483870967741935, 31),\n",
       "  (0.38461538461538464, 26),\n",
       "  (0.42857142857142855, 21),\n",
       "  (0.4375, 16),\n",
       "  (0.5, 12),\n",
       "  (0.42857142857142855, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9340446168768186, 2062),\n",
       "  (0.889955214331414, 1563),\n",
       "  (0.8544600938967136, 1278),\n",
       "  (0.8356164383561644, 1095),\n",
       "  (0.7960457856399584, 961),\n",
       "  (0.7861339600470035, 851),\n",
       "  (0.7806539509536785, 734),\n",
       "  (0.7625786163522013, 636),\n",
       "  (0.7661870503597122, 556),\n",
       "  (0.7663755458515283, 458),\n",
       "  (0.7688311688311689, 385),\n",
       "  (0.7346278317152104, 309),\n",
       "  (0.7426160337552743, 237),\n",
       "  (0.7777777777777778, 180),\n",
       "  (0.7703703703703704, 135),\n",
       "  (0.7884615384615384, 104),\n",
       "  (0.8133333333333334, 75),\n",
       "  (0.8125, 48),\n",
       "  (0.8148148148148148, 27),\n",
       "  (0.8666666666666667, 15),\n",
       "  (0.8333333333333334, 6),\n",
       "  (1.0, 6),\n",
       "  (0.5, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores_lstm, zeros_scores_lstm # lstm25, dense50, 50 epoch, .05 0s weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5569341e-01, 3.4430656e-01],\n",
       "       [8.2225472e-01, 1.7774528e-01],\n",
       "       [1.4185956e-01, 8.5814047e-01],\n",
       "       [9.7852433e-03, 9.9021471e-01],\n",
       "       [6.7260936e-03, 9.9327385e-01],\n",
       "       [4.9038115e-03, 9.9509615e-01],\n",
       "       [3.9083729e-03, 9.9609166e-01],\n",
       "       [2.8881221e-03, 9.9711180e-01],\n",
       "       [1.7733071e-03, 9.9822670e-01],\n",
       "       [1.0424535e-03, 9.9895751e-01],\n",
       "       [5.5245234e-04, 9.9944752e-01],\n",
       "       [3.1591905e-04, 9.9968410e-01],\n",
       "       [1.3631680e-04, 9.9986362e-01],\n",
       "       [4.3392138e-05, 9.9995661e-01],\n",
       "       [1.5405252e-05, 9.9998462e-01],\n",
       "       [8.4139618e-05, 9.9991584e-01],\n",
       "       [3.4838930e-02, 9.6516109e-01]], dtype=float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_player = X_all[np.where(player_ids_all == 'gehrilo01')]\n",
    "lstm.predict(X_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn(knn, X_test, y_test):\n",
    "    ones_preds, zeros_preds = None, None\n",
    "    try:\n",
    "        ones_preds = knn.predict([X_test[i] for i in np.where(y_test == 1)[0]])\n",
    "        print(np.sum(ones_preds) / len(ones_preds))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        zeros_preds = knn.predict([X_test[i] for i in np.where(y_test == 0)[0]])\n",
    "        print(np.sum(1-zeros_preds) / len(zeros_preds))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 big knn (0-padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eval on players at end of career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_end_career_knn(X_train, y_train, X_test, y_test, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=1, test_zeros_ratio=1, end_careers=True):\n",
    "    if train_zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_train_0s = np.where(y_train == 0)[0]\n",
    "        idxs_train_1s = np.where(y_train == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_train_0s, size=int(len(idxs_train_0s) * train_zeros_ratio), replace=False)\n",
    "        X_train_ratio_0s = [X_train[i] for i in ratio_0s] + [X_train[i] for i in idxs_train_1s]\n",
    "        y_train_ratio_0s = [y_train[i] for i in ratio_0s] + [y_train[i] for i in idxs_train_1s]\n",
    "    else:\n",
    "        X_train_ratio_0s = X_train\n",
    "        y_train_ratio_0s = y_train\n",
    "\n",
    "    knn_all = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "    knn_all.fit(X_train_ratio_0s, y_train_ratio_0s)\n",
    "    \n",
    "    if end_careers:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] == test_years_played[i]]\n",
    "        display(len(test_idxs_full_careers) / len(X_test))\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio))\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "#         print(idxs_sample_0s)\n",
    "        print(idxs)\n",
    "        eval_knn(knn_all, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        eval_knn(knn_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16960103375868196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1093  246 1129  933  988  148  132 1237 1335 1313  371  265  690  579\n",
      "  778 1562 1925 1144 2063 1061  333 1372 1957  330 1323  752  445  652\n",
      "  557 1128 1446 1513 1372  530  512 1647 1881 1395  911 1356   15   25\n",
      " 1530 1964 1341 1675 1078 1838 1184 1338  159  327  668 1347 1715  254\n",
      " 1407 1249  956 1789 1209  719 1380 1428 1906 1832 1312  476 1835  582\n",
      "  484 1513 1573 1647  739 1133 1099  547 1607  899 1836  993   99  282\n",
      " 1964  917  156 1775  625  504  156  911  893 1793 1927  279 1925 1911\n",
      "  341 1625 1460   20 2005   49   85   92  144  163  185  196  213  225\n",
      "  233  239  259  262  312  451  567  576  580  599  657  673  684  713\n",
      "  716  753  820  833  873  990 1006 1063 1068 1122 1130 1226 1706 1725\n",
      " 2024]\n",
      "0.2894736842105263\n",
      "0.9029126213592233\n"
     ]
    }
   ],
   "source": [
    "eval_end_career_knn(X_train, y_train, X_test, y_test, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=0.1, test_zeros_ratio=0.05, end_careers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn on specific year of careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_year_knn(yr, X_train, y_train, X_test, y_test, idx_train_by_year, idx_test_by_year, zeros_ratio=1):\n",
    "    idxs_train_yr, idxs_test_yr = np.array(idx_train_by_year[yr]), np.array(idx_test_by_year[yr])\n",
    "    \n",
    "    X_train_yr = [X_train_unpad[i] for i in idx_train_by_year[yr]]\n",
    "    y_train_yr = y_train[idx_train_by_year[yr]]\n",
    "    X_test_yr = [X_test_unpad[i] for i in idx_test_by_year[yr]]\n",
    "    y_test_yr = y_test[idx_test_by_year[yr]]\n",
    "    \n",
    "    if zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_yr_train_0s = np.where(y_train_yr == 0)[0]\n",
    "        idxs_yr_train_1s = np.where(y_train_yr == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_yr_train_0s, size=int(len(idxs_yr_train_0s) * zeros_ratio), replace=False)\n",
    "        X_train_yr_ratio_0s = [X_train_yr[i] for i in ratio_0s] + [X_train_yr[i] for i in idxs_yr_train_1s]\n",
    "        y_train_yr_ratio_0s = [y_train_yr[i] for i in ratio_0s] + [y_train_yr[i] for i in idxs_yr_train_1s]\n",
    "    else:\n",
    "        X_train_yr_ratio_0s = X_train_yr\n",
    "        y_train_yr_ratio_0s = y_train_yr\n",
    "    \n",
    "    display(np.where(y_test_yr == 1)[0])\n",
    "    \n",
    "    knn_yr = KNeighborsTimeSeriesClassifier(n_neighbors=1, metric='dtw')\n",
    "    knn_yr.fit(X_train_yr_ratio_0s, y_train_yr_ratio_0s)\n",
    "    \n",
    "    eval_knn(knn_yr, X_test_yr, y_test_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   5,   7,   9,  11,  13,  14,  15,  16,  17,  19,  22,  34,\n",
       "        39,  41,  44,  45,  49,  57,  62,  82,  88,  90,  93,  94, 136,\n",
       "       137, 142, 145, 148, 156, 162, 167])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36363636363636365\n",
      "0.8296296296296296\n"
     ]
    }
   ],
   "source": [
    "eval_year_knn(15, X_train, y_train, X_test, y_test, idx_train_by_year, idx_test_by_year, zeros_ratio=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
