{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tslearn\n",
    "!pip install pyts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.read_csv('../data_ready/agg/batting_norm_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>bb</th>\n",
       "      <th>double</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>hbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>player_id</th>\n",
       "      <th>r</th>\n",
       "      <th>rbi</th>\n",
       "      <th>sb</th>\n",
       "      <th>sh</th>\n",
       "      <th>so</th>\n",
       "      <th>triple</th>\n",
       "      <th>years_played</th>\n",
       "      <th>hof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.661588</td>\n",
       "      <td>-0.438871</td>\n",
       "      <td>-0.640879</td>\n",
       "      <td>-0.705525</td>\n",
       "      <td>-0.583966</td>\n",
       "      <td>-0.539028</td>\n",
       "      <td>-0.388342</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.539369</td>\n",
       "      <td>-0.609924</td>\n",
       "      <td>-0.335788</td>\n",
       "      <td>-0.665060</td>\n",
       "      <td>-0.794309</td>\n",
       "      <td>-0.310270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.145500</td>\n",
       "      <td>-0.634319</td>\n",
       "      <td>-1.124076</td>\n",
       "      <td>-1.026475</td>\n",
       "      <td>-1.017650</td>\n",
       "      <td>-1.125153</td>\n",
       "      <td>-0.813317</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.903027</td>\n",
       "      <td>-1.153566</td>\n",
       "      <td>-0.636014</td>\n",
       "      <td>-1.424980</td>\n",
       "      <td>-0.892177</td>\n",
       "      <td>-0.404662</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.161406</td>\n",
       "      <td>-0.031041</td>\n",
       "      <td>-1.378979</td>\n",
       "      <td>-0.693510</td>\n",
       "      <td>-1.160762</td>\n",
       "      <td>-0.056680</td>\n",
       "      <td>-1.235447</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-0.879855</td>\n",
       "      <td>-1.079926</td>\n",
       "      <td>-0.389503</td>\n",
       "      <td>-1.058649</td>\n",
       "      <td>-1.112142</td>\n",
       "      <td>-0.762685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.954610</td>\n",
       "      <td>-0.615781</td>\n",
       "      <td>-2.052017</td>\n",
       "      <td>-1.647343</td>\n",
       "      <td>-1.893377</td>\n",
       "      <td>-0.604941</td>\n",
       "      <td>-1.638442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.575987</td>\n",
       "      <td>-1.775687</td>\n",
       "      <td>-0.956969</td>\n",
       "      <td>-1.764229</td>\n",
       "      <td>-2.108656</td>\n",
       "      <td>-1.364642</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.744661</td>\n",
       "      <td>-0.229190</td>\n",
       "      <td>-2.314481</td>\n",
       "      <td>-1.438181</td>\n",
       "      <td>-1.531243</td>\n",
       "      <td>-1.148788</td>\n",
       "      <td>-2.011442</td>\n",
       "      <td>acostme01</td>\n",
       "      <td>-1.190280</td>\n",
       "      <td>-1.700775</td>\n",
       "      <td>-0.966303</td>\n",
       "      <td>-1.027140</td>\n",
       "      <td>-2.202136</td>\n",
       "      <td>-0.952990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43686</th>\n",
       "      <td>-0.448198</td>\n",
       "      <td>-0.350041</td>\n",
       "      <td>-0.506754</td>\n",
       "      <td>-0.542378</td>\n",
       "      <td>-0.443520</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>turnetr01</td>\n",
       "      <td>-0.407728</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.390894</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43687</th>\n",
       "      <td>0.781068</td>\n",
       "      <td>0.410928</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.614127</td>\n",
       "      <td>0.573732</td>\n",
       "      <td>0.309030</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>urshegi01</td>\n",
       "      <td>0.382690</td>\n",
       "      <td>0.258928</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>0.058954</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43688</th>\n",
       "      <td>-0.659393</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-1.099213</td>\n",
       "      <td>-0.623035</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>waldrky02</td>\n",
       "      <td>-0.605333</td>\n",
       "      <td>-0.587657</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.663400</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43689</th>\n",
       "      <td>-0.551088</td>\n",
       "      <td>-0.513105</td>\n",
       "      <td>-0.308580</td>\n",
       "      <td>-0.949296</td>\n",
       "      <td>-0.503358</td>\n",
       "      <td>-0.452528</td>\n",
       "      <td>-0.364299</td>\n",
       "      <td>willima07</td>\n",
       "      <td>-0.486770</td>\n",
       "      <td>-0.466716</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.613853</td>\n",
       "      <td>-0.427949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43690</th>\n",
       "      <td>-0.491520</td>\n",
       "      <td>-0.567460</td>\n",
       "      <td>-0.605841</td>\n",
       "      <td>-0.906462</td>\n",
       "      <td>-0.483412</td>\n",
       "      <td>-0.071749</td>\n",
       "      <td>-0.502202</td>\n",
       "      <td>willima08</td>\n",
       "      <td>-0.526291</td>\n",
       "      <td>-0.547344</td>\n",
       "      <td>-0.357982</td>\n",
       "      <td>-0.478008</td>\n",
       "      <td>-0.489987</td>\n",
       "      <td>0.186402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43691 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ab        bb    double         g         h       hbp        hr  \\\n",
       "0     -0.661588 -0.438871 -0.640879 -0.705525 -0.583966 -0.539028 -0.388342   \n",
       "1     -1.145500 -0.634319 -1.124076 -1.026475 -1.017650 -1.125153 -0.813317   \n",
       "2     -1.161406 -0.031041 -1.378979 -0.693510 -1.160762 -0.056680 -1.235447   \n",
       "3     -1.954610 -0.615781 -2.052017 -1.647343 -1.893377 -0.604941 -1.638442   \n",
       "4     -1.744661 -0.229190 -2.314481 -1.438181 -1.531243 -1.148788 -2.011442   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "43686 -0.448198 -0.350041 -0.506754 -0.542378 -0.443520 -0.452528 -0.364299   \n",
       "43687  0.781068  0.410928  0.186854  0.614127  0.573732  0.309030  0.325219   \n",
       "43688 -0.659393 -0.567460 -0.605841 -1.099213 -0.623035 -0.452528 -0.502202   \n",
       "43689 -0.551088 -0.513105 -0.308580 -0.949296 -0.503358 -0.452528 -0.364299   \n",
       "43690 -0.491520 -0.567460 -0.605841 -0.906462 -0.483412 -0.071749 -0.502202   \n",
       "\n",
       "       player_id         r       rbi        sb        sh        so    triple  \\\n",
       "0      acostme01 -0.539369 -0.609924 -0.335788 -0.665060 -0.794309 -0.310270   \n",
       "1      acostme01 -0.903027 -1.153566 -0.636014 -1.424980 -0.892177 -0.404662   \n",
       "2      acostme01 -0.879855 -1.079926 -0.389503 -1.058649 -1.112142 -0.762685   \n",
       "3      acostme01 -1.575987 -1.775687 -0.956969 -1.764229 -2.108656 -1.364642   \n",
       "4      acostme01 -1.190280 -1.700775 -0.966303 -1.027140 -2.202136 -0.952990   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "43686  turnetr01 -0.407728 -0.547344  0.027295 -0.478008 -0.390894 -0.427949   \n",
       "43687  urshegi01  0.382690  0.258928 -0.357982  0.058954  0.748672  0.186402   \n",
       "43688  waldrky02 -0.605333 -0.587657 -0.357982 -0.478008 -0.663400 -0.427949   \n",
       "43689  willima07 -0.486770 -0.466716 -0.357982 -0.478008 -0.613853 -0.427949   \n",
       "43690  willima08 -0.526291 -0.547344 -0.357982 -0.478008 -0.489987  0.186402   \n",
       "\n",
       "       years_played    hof  \n",
       "0               1.0  False  \n",
       "1               2.0  False  \n",
       "2               3.0  False  \n",
       "3               4.0  False  \n",
       "4               5.0  False  \n",
       "...             ...    ...  \n",
       "43686           1.0  False  \n",
       "43687           1.0  False  \n",
       "43688           1.0  False  \n",
       "43689           1.0  False  \n",
       "43690           1.0  False  \n",
       "\n",
       "[43691 rows x 16 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_length = agg_df.groupby('player_id')['years_played'].max()\n",
    "players_5yrs = career_length[career_length > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the time series samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches:\n",
    "* Zero pad, and throw into one time series classifier  \n",
    "* Train one time series classifier for each length (1-year careers, 2-year careers, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load('../data_ready/ts/X_all.npy')\n",
    "y_all = np.load('../data_ready/y_all.npy')\n",
    "years_played_all = np.load('../data_ready/years_played_all.npy')\n",
    "player_ids_all = np.load('../data_ready/player_ids_all.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test split by HOF / non-hof players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_players = agg_df[agg_df['hof']]['player_id'].unique()\n",
    "non_hof_players = agg_df[~agg_df['hof']]['player_id'].unique()\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(hof_players), np.random.shuffle(non_hof_players);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "zeros_ratio = 1\n",
    "n_hof, n_non = len(hof_players), len(non_hof_players)\n",
    "\n",
    "train_hof, test_hof = hof_players[:int(n_hof*train_ratio)], hof_players[int(n_hof*train_ratio):]\n",
    "train_non, test_non = non_hof_players[:int(n_non*train_ratio)], non_hof_players[int(n_non*train_ratio):]\n",
    "\n",
    "train_non_sample = train_non[:int(len(train_non)*zeros_ratio)]\n",
    "\n",
    "train_players, test_players = set(np.concatenate((train_hof, train_non_sample))), set(np.concatenate((test_hof, test_non)))\n",
    "train_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in train_players])\n",
    "test_idxs = np.array([i for i in range(len(player_ids_all)) if player_ids_all[i] in test_players])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_all[train_idxs], X_all[test_idxs]\n",
    "y_train, y_test = y_all[train_idxs], y_all[test_idxs]\n",
    "train_years_played, test_years_played = years_played_all[train_idxs], years_played_all[test_idxs]\n",
    "train_player_ids, test_player_ids = player_ids_all[train_idxs], player_ids_all[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undo zero-padding + group idxs by # of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unpad, X_test_unpad = [], []\n",
    "idx_train_by_year, idx_test_by_year = [[] for _ in range(26)], [[] for _ in range(26)]\n",
    "for i in range(X_train.shape[0]):\n",
    "    yrs_played = int(train_years_played[i])\n",
    "    idx_train_by_year[yrs_played].append(i)\n",
    "    X_train_unpad.append(X_train[i][:yrs_played])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yrs_played = int(test_years_played[i])\n",
    "    idx_test_by_year[yrs_played].append(i)\n",
    "    X_test_unpad.append(X_test[i][:yrs_played])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of HOFers + # of samples for each career length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.01791166293507022, 4913),\n",
       " (0.023441662226957913, 3754),\n",
       " (0.02861788617886179, 3075),\n",
       " (0.033820138355111454, 2602),\n",
       " (0.03951504265828469, 2227),\n",
       " (0.0446927374301676, 1969),\n",
       " (0.05086705202312139, 1730),\n",
       " (0.05778069599474721, 1523),\n",
       " (0.06722689075630252, 1309),\n",
       " (0.07963800904977375, 1105),\n",
       " (0.09209100758396534, 923),\n",
       " (0.11413043478260869, 736),\n",
       " (0.14513274336283186, 565),\n",
       " (0.16591928251121077, 446),\n",
       " (0.20057306590257878, 349),\n",
       " (0.252, 250),\n",
       " (0.3191489361702128, 188),\n",
       " (0.425, 120),\n",
       " (0.5443037974683544, 79),\n",
       " (0.7021276595744681, 47),\n",
       " (0.78125, 32),\n",
       " (0.8571428571428571, 21),\n",
       " (0.8, 10),\n",
       " (0.75, 4),\n",
       " (1.0, 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-223-ff41d8fec79c>:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.018095238095238095, 2100),\n",
       " (0.023125, 1600),\n",
       " (0.028136882129277566, 1315),\n",
       " (0.03268551236749117, 1132),\n",
       " (0.03707414829659319, 998),\n",
       " (0.041666666666666664, 888),\n",
       " (0.04798962386511025, 771),\n",
       " (0.0549777117384844, 673),\n",
       " (0.060810810810810814, 592),\n",
       " (0.0728744939271255, 494),\n",
       " (0.08333333333333333, 420),\n",
       " (0.10174418604651163, 344),\n",
       " (0.12546125461254612, 271),\n",
       " (0.1588785046728972, 214),\n",
       " (0.19642857142857142, 168),\n",
       " (0.22962962962962963, 135),\n",
       " (0.25742574257425743, 101),\n",
       " (0.30434782608695654, 69),\n",
       " (0.37209302325581395, 43),\n",
       " (0.4444444444444444, 27),\n",
       " (0.5384615384615384, 13),\n",
       " (0.4, 10),\n",
       " (0.3333333333333333, 3),\n",
       " (0.0, 1),\n",
       " (nan, 0)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training data')\n",
    "train_hist = [(np.sum(y_train[idx_train_by_year[i]]) / len(idx_train_by_year[i]), len(idx_train_by_year[i])) for i in range(1, 26)]\n",
    "display(train_hist)\n",
    "print('test data')\n",
    "test_hist = [(np.sum(y_test[idx_test_by_year[i]]) / len(idx_test_by_year[i]), len(idx_test_by_year[i])) for i in range(1, 26)]\n",
    "test_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random HOF and non-HOF samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "hof_rand, non_hof_rand = np.random.choice(np.where(y_train == 1)[0]), np.random.choice(np.where(y_train == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1397146 ,  2.02168166,  1.67783737,  1.08165126,  0.79330746,\n",
       "         0.4307195 ,  1.43247401,  1.64431773,  0.89903381,  3.21099742,\n",
       "         0.01175137,  2.02244887,  0.97868075],\n",
       "       [ 1.83910241,  1.49446174,  2.36819163,  1.85646077,  1.6838071 ,\n",
       "         0.92022933,  2.13481438,  2.35548097,  1.15177433,  2.77268543,\n",
       "        -0.66056693,  1.58710637,  3.81924303]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bondsba01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.57857528, -0.59401745, -0.6408787 , -0.56246791, -0.60335458,\n",
       "        -0.53902771,  0.0925411 , -0.42471865, -0.56422656, -0.3357883 ,\n",
       "        -0.66506004, -0.3957359 , -0.57427077]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'thorpji01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in (hof_rand, non_hof_rand):\n",
    "    display(X_train_unpad[i], train_years_played[i], train_player_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCKET \n",
    "hinge: train in 70 sec, 90 epochs  \n",
    "log: train in 150 sec, 101 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Trying 70/30 splits because 80/20 gives too few 'full career' test samples of HOFers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sktime.transformers.series_as_features.rocket import Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket(rocket_pipeline, X_test, y_test):\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "#         print('ones ({})'.format(np.sum(y_test)))\n",
    "        ones_preds = rocket_pipeline.predict_proba(X_test[y_test == 1])\n",
    "        ones_score = np.sum(np.argmax(ones_preds, axis=1)) / len(ones_preds)\n",
    "#         print(ones_score)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "#         print('zeros ({})'.format(np.sum(1-y_test)))\n",
    "        zeros_preds = rocket_pipeline.predict_proba(X_test[y_test == 0])\n",
    "        zeros_score = np.sum(1-np.argmax(zeros_preds, axis=1)) / len(zeros_preds)\n",
    "#         print(zeros_score)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rocket_by_year(rocket_pipeline, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "    \n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "\n",
    "        return eval_rocket(rocket_pipeline, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_rocket(rocket_pipeline, X_test, y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_sgd = make_pipeline(Rocket(), SGDClassifier(loss='log', eta0=0.001, learning_rate='adaptive', verbose=1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 10.71, NNZs: 20000, Bias: -0.003125, T: 27978, Avg. loss: 4.955015\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.55, NNZs: 20000, Bias: -0.001824, T: 55956, Avg. loss: 2.492977\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.11, NNZs: 20000, Bias: -0.003396, T: 83934, Avg. loss: 1.658427\n",
      "Total training time: 3.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.90, NNZs: 20000, Bias: -0.002649, T: 111912, Avg. loss: 1.307963\n",
      "Total training time: 4.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20.35, NNZs: 20000, Bias: -0.003238, T: 139890, Avg. loss: 1.047719\n",
      "Total training time: 6.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.49, NNZs: 20000, Bias: -0.004017, T: 167868, Avg. loss: 0.879933\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.29, NNZs: 20000, Bias: -0.003272, T: 195846, Avg. loss: 0.736593\n",
      "Total training time: 8.70 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 22.94, NNZs: 20000, Bias: -0.003158, T: 223824, Avg. loss: 0.629732\n",
      "Total training time: 9.93 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 23.64, NNZs: 20000, Bias: -0.005069, T: 251802, Avg. loss: 0.608024\n",
      "Total training time: 11.17 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 24.17, NNZs: 20000, Bias: -0.004460, T: 279780, Avg. loss: 0.516063\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 24.71, NNZs: 20000, Bias: -0.005255, T: 307758, Avg. loss: 0.503959\n",
      "Total training time: 13.66 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 25.28, NNZs: 20000, Bias: -0.005173, T: 335736, Avg. loss: 0.503133\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 25.74, NNZs: 20000, Bias: -0.005473, T: 363714, Avg. loss: 0.436114\n",
      "Total training time: 16.13 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 26.03, NNZs: 20000, Bias: -0.004034, T: 391692, Avg. loss: 0.358027\n",
      "Total training time: 17.36 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 26.39, NNZs: 20000, Bias: -0.005488, T: 419670, Avg. loss: 0.375860\n",
      "Total training time: 18.60 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 26.69, NNZs: 20000, Bias: -0.006421, T: 447648, Avg. loss: 0.332289\n",
      "Total training time: 19.85 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 26.98, NNZs: 20000, Bias: -0.005717, T: 475626, Avg. loss: 0.341965\n",
      "Total training time: 21.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27.24, NNZs: 20000, Bias: -0.005392, T: 503604, Avg. loss: 0.324829\n",
      "Total training time: 22.33 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27.49, NNZs: 20000, Bias: -0.004602, T: 531582, Avg. loss: 0.310947\n",
      "Total training time: 23.56 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27.73, NNZs: 20000, Bias: -0.004264, T: 559560, Avg. loss: 0.322480\n",
      "Total training time: 24.80 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 28.00, NNZs: 20000, Bias: -0.004535, T: 587538, Avg. loss: 0.303889\n",
      "Total training time: 26.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 28.22, NNZs: 20000, Bias: -0.005665, T: 615516, Avg. loss: 0.280860\n",
      "Total training time: 27.26 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 28.50, NNZs: 20000, Bias: -0.004826, T: 643494, Avg. loss: 0.298082\n",
      "Total training time: 28.50 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 28.66, NNZs: 20000, Bias: -0.004010, T: 671472, Avg. loss: 0.266973\n",
      "Total training time: 29.74 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 28.83, NNZs: 20000, Bias: -0.003979, T: 699450, Avg. loss: 0.268160\n",
      "Total training time: 30.97 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28.92, NNZs: 20000, Bias: -0.005345, T: 727428, Avg. loss: 0.218963\n",
      "Total training time: 32.20 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 29.02, NNZs: 20000, Bias: -0.005319, T: 755406, Avg. loss: 0.227002\n",
      "Total training time: 33.45 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 29.16, NNZs: 20000, Bias: -0.005856, T: 783384, Avg. loss: 0.229743\n",
      "Total training time: 34.71 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 29.29, NNZs: 20000, Bias: -0.006702, T: 811362, Avg. loss: 0.200506\n",
      "Total training time: 36.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 29.39, NNZs: 20000, Bias: -0.006814, T: 839340, Avg. loss: 0.201608\n",
      "Total training time: 37.28 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 29.55, NNZs: 20000, Bias: -0.006801, T: 867318, Avg. loss: 0.225222\n",
      "Total training time: 38.53 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 29.71, NNZs: 20000, Bias: -0.005644, T: 895296, Avg. loss: 0.214238\n",
      "Total training time: 39.78 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 29.82, NNZs: 20000, Bias: -0.004482, T: 923274, Avg. loss: 0.215211\n",
      "Total training time: 41.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 29.94, NNZs: 20000, Bias: -0.005748, T: 951252, Avg. loss: 0.197164\n",
      "Total training time: 42.31 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 30.08, NNZs: 20000, Bias: -0.005586, T: 979230, Avg. loss: 0.192406\n",
      "Total training time: 43.56 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 30.15, NNZs: 20000, Bias: -0.005454, T: 1007208, Avg. loss: 0.179748\n",
      "Total training time: 44.80 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 30.26, NNZs: 20000, Bias: -0.006545, T: 1035186, Avg. loss: 0.180308\n",
      "Total training time: 46.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 30.36, NNZs: 20000, Bias: -0.006349, T: 1063164, Avg. loss: 0.171909\n",
      "Total training time: 47.28 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 30.42, NNZs: 20000, Bias: -0.006147, T: 1091142, Avg. loss: 0.172182\n",
      "Total training time: 48.52 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 30.54, NNZs: 20000, Bias: -0.006973, T: 1119120, Avg. loss: 0.194986\n",
      "Total training time: 49.76 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 30.60, NNZs: 20000, Bias: -0.006851, T: 1147098, Avg. loss: 0.165624\n",
      "Total training time: 51.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 30.72, NNZs: 20000, Bias: -0.005570, T: 1175076, Avg. loss: 0.189360\n",
      "Total training time: 52.23 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 30.78, NNZs: 20000, Bias: -0.006429, T: 1203054, Avg. loss: 0.153479\n",
      "Total training time: 53.47 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 30.87, NNZs: 20000, Bias: -0.006305, T: 1231032, Avg. loss: 0.157629\n",
      "Total training time: 54.70 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 30.94, NNZs: 20000, Bias: -0.005980, T: 1259010, Avg. loss: 0.158965\n",
      "Total training time: 55.94 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 31.02, NNZs: 20000, Bias: -0.007553, T: 1286988, Avg. loss: 0.150408\n",
      "Total training time: 57.18 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 31.16, NNZs: 20000, Bias: -0.005292, T: 1314966, Avg. loss: 0.180233\n",
      "Total training time: 58.42 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 31.19, NNZs: 20000, Bias: -0.006540, T: 1342944, Avg. loss: 0.132770\n",
      "Total training time: 59.66 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 31.23, NNZs: 20000, Bias: -0.006234, T: 1370922, Avg. loss: 0.136873\n",
      "Total training time: 60.90 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 31.34, NNZs: 20000, Bias: -0.006047, T: 1398900, Avg. loss: 0.181115\n",
      "Total training time: 62.14 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 31.39, NNZs: 20000, Bias: -0.006596, T: 1426878, Avg. loss: 0.136550\n",
      "Total training time: 63.37 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 31.51, NNZs: 20000, Bias: -0.007460, T: 1454856, Avg. loss: 0.154394\n",
      "Total training time: 64.67 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 31.56, NNZs: 20000, Bias: -0.006969, T: 1482834, Avg. loss: 0.145017\n",
      "Total training time: 65.92 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 31.54, NNZs: 20000, Bias: -0.006816, T: 1510812, Avg. loss: 0.042583\n",
      "Total training time: 67.19 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 31.52, NNZs: 20000, Bias: -0.006651, T: 1538790, Avg. loss: 0.036241\n",
      "Total training time: 68.43 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 31.50, NNZs: 20000, Bias: -0.006633, T: 1566768, Avg. loss: 0.032497\n",
      "Total training time: 69.68 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 31.48, NNZs: 20000, Bias: -0.006043, T: 1594746, Avg. loss: 0.028312\n",
      "Total training time: 70.92 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 31.46, NNZs: 20000, Bias: -0.006478, T: 1622724, Avg. loss: 0.029063\n",
      "Total training time: 72.19 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 31.44, NNZs: 20000, Bias: -0.006556, T: 1650702, Avg. loss: 0.028395\n",
      "Total training time: 73.44 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 31.42, NNZs: 20000, Bias: -0.006725, T: 1678680, Avg. loss: 0.027270\n",
      "Total training time: 74.68 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 31.40, NNZs: 20000, Bias: -0.006314, T: 1706658, Avg. loss: 0.027182\n",
      "Total training time: 75.93 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 31.38, NNZs: 20000, Bias: -0.006372, T: 1734636, Avg. loss: 0.026504\n",
      "Total training time: 77.17 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 31.36, NNZs: 20000, Bias: -0.006431, T: 1762614, Avg. loss: 0.026935\n",
      "Total training time: 78.42 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 31.34, NNZs: 20000, Bias: -0.006447, T: 1790592, Avg. loss: 0.026417\n",
      "Total training time: 79.66 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 31.32, NNZs: 20000, Bias: -0.006582, T: 1818570, Avg. loss: 0.025053\n",
      "Total training time: 80.92 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 31.30, NNZs: 20000, Bias: -0.006606, T: 1846548, Avg. loss: 0.023932\n",
      "Total training time: 82.16 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 31.29, NNZs: 20000, Bias: -0.006477, T: 1874526, Avg. loss: 0.023694\n",
      "Total training time: 83.40 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 31.27, NNZs: 20000, Bias: -0.006680, T: 1902504, Avg. loss: 0.023047\n",
      "Total training time: 84.65 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 31.25, NNZs: 20000, Bias: -0.006456, T: 1930482, Avg. loss: 0.024014\n",
      "Total training time: 85.92 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 31.23, NNZs: 20000, Bias: -0.006526, T: 1958460, Avg. loss: 0.023186\n",
      "Total training time: 87.17 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 31.21, NNZs: 20000, Bias: -0.006505, T: 1986438, Avg. loss: 0.022197\n",
      "Total training time: 88.42 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 31.21, NNZs: 20000, Bias: -0.006484, T: 2014416, Avg. loss: 0.017222\n",
      "Total training time: 89.70 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 31.20, NNZs: 20000, Bias: -0.006476, T: 2042394, Avg. loss: 0.016908\n",
      "Total training time: 90.96 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 31.20, NNZs: 20000, Bias: -0.006493, T: 2070372, Avg. loss: 0.017028\n",
      "Total training time: 92.22 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 31.19, NNZs: 20000, Bias: -0.006524, T: 2098350, Avg. loss: 0.017128\n",
      "Total training time: 93.47 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 31.19, NNZs: 20000, Bias: -0.006553, T: 2126328, Avg. loss: 0.017019\n",
      "Total training time: 94.73 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 31.19, NNZs: 20000, Bias: -0.006529, T: 2154306, Avg. loss: 0.017114\n",
      "Total training time: 95.98 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006492, T: 2182284, Avg. loss: 0.015828\n",
      "Total training time: 97.24 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006487, T: 2210262, Avg. loss: 0.015934\n",
      "Total training time: 98.49 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006514, T: 2238240, Avg. loss: 0.015989\n",
      "Total training time: 99.74 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006522, T: 2266218, Avg. loss: 0.015829\n",
      "Total training time: 100.99 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006508, T: 2294196, Avg. loss: 0.015951\n",
      "Total training time: 102.24 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006503, T: 2322174, Avg. loss: 0.015933\n",
      "Total training time: 103.48 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006505, T: 2350152, Avg. loss: 0.015680\n",
      "Total training time: 104.72 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006511, T: 2378130, Avg. loss: 0.015654\n",
      "Total training time: 105.96 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006511, T: 2406108, Avg. loss: 0.015665\n",
      "Total training time: 107.21 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006506, T: 2434086, Avg. loss: 0.015653\n",
      "Total training time: 108.45 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006500, T: 2462064, Avg. loss: 0.015616\n",
      "Total training time: 109.69 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006502, T: 2490042, Avg. loss: 0.015633\n",
      "Total training time: 110.94 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006503, T: 2518020, Avg. loss: 0.015621\n",
      "Total training time: 112.19 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006504, T: 2545998, Avg. loss: 0.015614\n",
      "Total training time: 113.43 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006505, T: 2573976, Avg. loss: 0.015610\n",
      "Total training time: 114.69 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 31.18, NNZs: 20000, Bias: -0.006506, T: 2601954, Avg. loss: 0.015608\n",
      "Total training time: 115.93 seconds.\n",
      "Convergence after 93 epochs took 115.93 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rocket', Rocket()),\n",
       "                ('sgdclassifier',\n",
       "                 SGDClassifier(eta0=0.001, learning_rate='adaptive', loss='log',\n",
       "                               verbose=1))])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocket_pipeline_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.2894736842105263, 38), (0.986905916585839, 2062))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=0)\n",
    "ones_score, zeros_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_preds, zeros_preds, ones_scores, zeros_scores = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_sgd, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores.append(ones_score), zeros_scores.append(zeros_score)\n",
    "    ones_preds.append(ones_pred), zeros_preds.append(zeros_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.max(axis=1).mean(axis=0) for x in ones_preds if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.2894736842105263, 38),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.1891891891891892, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.19444444444444445, 36),\n",
       "  (0.16666666666666666, 36),\n",
       "  (0.14285714285714285, 35),\n",
       "  (0.11428571428571428, 35),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.06060606060606061, 33),\n",
       "  (0.0967741935483871, 31),\n",
       "  (0.0, 26),\n",
       "  (0.047619047619047616, 21),\n",
       "  (0.0, 16),\n",
       "  (0.0, 12),\n",
       "  (0.14285714285714285, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.986905916585839, 2062),\n",
       "  (0.9865642994241842, 1563),\n",
       "  (0.9843505477308294, 1278),\n",
       "  (0.9808219178082191, 1095),\n",
       "  (0.9729448491155047, 961),\n",
       "  (0.9647473560517039, 851),\n",
       "  (0.9754768392370572, 734),\n",
       "  (0.9732704402515723, 636),\n",
       "  (0.9730215827338129, 556),\n",
       "  (0.9737991266375546, 458),\n",
       "  (0.9636363636363636, 385),\n",
       "  (0.970873786407767, 309),\n",
       "  (0.9746835443037974, 237),\n",
       "  (0.9777777777777777, 180),\n",
       "  (0.9629629629629629, 135),\n",
       "  (0.9807692307692307, 104),\n",
       "  (0.9733333333333334, 75),\n",
       "  (1.0, 48),\n",
       "  (1.0, 27),\n",
       "  (0.9333333333333333, 15),\n",
       "  (1.0, 6),\n",
       "  (1.0, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores, zeros_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.2894736842105263, 38),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.21621621621621623, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.13513513513513514, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.16216216216216217, 37),\n",
       "  (0.1111111111111111, 36),\n",
       "  (0.1111111111111111, 36),\n",
       "  (0.08571428571428572, 35),\n",
       "  (0.05714285714285714, 35),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.08823529411764706, 34),\n",
       "  (0.0, 33),\n",
       "  (0.03225806451612903, 31),\n",
       "  (0.0, 26),\n",
       "  (0.19047619047619047, 21),\n",
       "  (0.0, 16),\n",
       "  (0.08333333333333333, 12),\n",
       "  (0.14285714285714285, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9742967992240543, 2062),\n",
       "  (0.9833653230966091, 1563),\n",
       "  (0.9780907668231612, 1278),\n",
       "  (0.9780821917808219, 1095),\n",
       "  (0.9802289281997919, 961),\n",
       "  (0.972972972972973, 851),\n",
       "  (0.9754768392370572, 734),\n",
       "  (0.9685534591194969, 636),\n",
       "  (0.960431654676259, 556),\n",
       "  (0.9716157205240175, 458),\n",
       "  (0.9558441558441558, 385),\n",
       "  (0.948220064724919, 309),\n",
       "  (0.9535864978902954, 237),\n",
       "  (0.9666666666666667, 180),\n",
       "  (0.9629629629629629, 135),\n",
       "  (0.9615384615384616, 104),\n",
       "  (0.9333333333333333, 75),\n",
       "  (0.9583333333333334, 48),\n",
       "  (1.0, 27),\n",
       "  (0.9333333333333333, 15),\n",
       "  (1.0, 6),\n",
       "  (1.0, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores, zeros_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket_pipeline_lr = make_pipeline(Rocket(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rocket', Rocket()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocket_pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_preds_lr, zeros_preds_lr, ones_scores_lr, zeros_scores_lr = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_rocket_by_year(rocket_pipeline_lr, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores_lr.append(ones_score), zeros_scores_lr.append(zeros_score)\n",
    "    ones_preds_lr.append(ones_pred), zeros_preds_lr.append(zeros_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9728662059137236,\n",
       " 0.9929342601925164,\n",
       " 0.99346416387623,\n",
       " 0.9967988207994575,\n",
       " 0.9909905834569106,\n",
       " 0.9765439904964117,\n",
       " 0.9949735651804014,\n",
       " 0.9598247171690968,\n",
       " 0.9768766756414441,\n",
       " 0.9469910682985063,\n",
       " 0.9434483565245709,\n",
       " 0.9637201689063353,\n",
       " 0.8862348063154448,\n",
       " 0.9023997168849658,\n",
       " 0.9327165148198022,\n",
       " 0.8996094527926582,\n",
       " 0.9511596148214464,\n",
       " 0.9165886934148301,\n",
       " 0.9456244967745924,\n",
       " 0.9451336230178454,\n",
       " 0.9314653422498586,\n",
       " 0.8932411574535032,\n",
       " 0.9950144202879145]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.max(axis=1).mean(axis=0) for x in ones_preds_lr if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.9444444444444444, 36),\n",
       "  (0.9761904761904762, 42),\n",
       "  (0.967741935483871, 31),\n",
       "  (0.9761904761904762, 42),\n",
       "  (1.0, 40),\n",
       "  (1.0, 45),\n",
       "  (1.0, 38),\n",
       "  (0.9333333333333333, 30),\n",
       "  (0.9777777777777777, 45),\n",
       "  (0.9210526315789473, 38),\n",
       "  (0.9142857142857143, 35),\n",
       "  (0.8529411764705882, 34),\n",
       "  (0.6666666666666666, 21),\n",
       "  (0.7105263157894737, 38),\n",
       "  (0.6206896551724138, 29),\n",
       "  (0.6071428571428571, 28),\n",
       "  (0.4230769230769231, 26),\n",
       "  (0.4166666666666667, 24),\n",
       "  (0.29411764705882354, 17),\n",
       "  (0.14285714285714285, 14),\n",
       "  (0.2222222222222222, 9),\n",
       "  (0.5, 8),\n",
       "  (0.0, 2),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9985822306238186, 2116),\n",
       "  (0.9955974842767296, 1590),\n",
       "  (0.9960063897763578, 1252),\n",
       "  (0.9953401677539608, 1073),\n",
       "  (0.997920997920998, 962),\n",
       "  (0.9939172749391727, 822),\n",
       "  (0.9945130315500685, 729),\n",
       "  (0.9950166112956811, 602),\n",
       "  (0.9881188118811881, 505),\n",
       "  (0.9909706546275395, 443),\n",
       "  (0.9886039886039886, 351),\n",
       "  (0.9965034965034965, 286),\n",
       "  (0.9950980392156863, 204),\n",
       "  (0.9942528735632183, 174),\n",
       "  (1.0, 119),\n",
       "  (0.9868421052631579, 76),\n",
       "  (0.9682539682539683, 63),\n",
       "  (1.0, 36),\n",
       "  (1.0, 16),\n",
       "  (0.8888888888888888, 9),\n",
       "  (1.0, 3),\n",
       "  (1.0, 3),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores_lr, zeros_scores_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainX, trainy):\n",
    "    verbose, epochs, batch_size = 1, 20, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(LSTM(100, input_shape=(100,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose, class_weight={0:0.056, 1:1.0})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm(lstm, X_test, y_test):\n",
    "    ones_preds, zeros_preds, ones_score, zeros_score = None, None, None, None\n",
    "    n_ones = np.sum(y_test)\n",
    "    n_zeros = np.sum(1-y_test)\n",
    "    try:\n",
    "#         print('ones ({})'.format(np.sum(y_test)))\n",
    "        ones_preds = lstm.predict(X_test[y_test == 1], batch_size=64, verbose=0)\n",
    "\n",
    "        ones_score = np.sum(np.argmax(ones_preds, axis=1)) / len(ones_preds)\n",
    "#         print(ones_score)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "#         print('zeros ({})'.format(np.sum(1-y_test)))\n",
    "        zeros_preds = lstm.predict(X_test[y_test == 0], batch_size=64, verbose=0)\n",
    "        zeros_score = np.sum(1-np.argmax(zeros_preds, axis=1)) / len(zeros_preds)\n",
    "#         print(zeros_score)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds, (ones_score, n_ones), (zeros_score, n_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, test_zeros_ratio=1, years_before_end=-1):\n",
    "    \n",
    "    if years_before_end != -1:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] - years_before_end == test_years_played[i]]\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio), replace=False)\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "\n",
    "        return eval_lstm(lstm, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        return eval_rocket(lstm, X_test, y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05647294302666381"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_16 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-7480ed8773b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-269-d617175cb025>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainX, trainy)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    926\u001b[0m                                                 input_list)\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    177\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_16 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 100]"
     ]
    }
   ],
   "source": [
    "lstm = train_model(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_preds_lstm, zeros_preds_lstm, ones_scores_lstm, zeros_scores_lstm = [], [], [], []\n",
    "for i in range(26):\n",
    "    ones_pred, zeros_pred, ones_score, zeros_score = eval_lstm_by_year(lstm, X_test, y_test, agg_df, test_player_ids, test_years_played, years_before_end=i)\n",
    "    ones_scores_lstm.append(ones_score), zeros_scores_lstm.append(zeros_score)\n",
    "    ones_preds_lstm.append(ones_pred), zeros_preds_lstm.append(zeros_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.2354128e-01, 1.7645872e-01],\n",
       "       [1.5211278e-01, 8.4788722e-01],\n",
       "       [9.5069297e-02, 9.0493071e-01],\n",
       "       [5.3681238e-03, 9.9463189e-01],\n",
       "       [2.4270816e-03, 9.9757296e-01],\n",
       "       [1.6701411e-03, 9.9832982e-01],\n",
       "       [2.0846217e-03, 9.9791533e-01],\n",
       "       [1.8395528e-03, 9.9816042e-01],\n",
       "       [1.3342579e-03, 9.9866569e-01],\n",
       "       [1.2906342e-03, 9.9870932e-01],\n",
       "       [1.1719392e-03, 9.9882811e-01],\n",
       "       [1.0368337e-03, 9.9896312e-01],\n",
       "       [1.4069162e-03, 9.9859303e-01],\n",
       "       [2.0288890e-03, 9.9797112e-01],\n",
       "       [1.6506033e-03, 9.9834943e-01],\n",
       "       [1.1700179e-03, 9.9883002e-01],\n",
       "       [7.1390590e-04, 9.9928612e-01],\n",
       "       [6.4166368e-04, 9.9935836e-01],\n",
       "       [2.9888004e-01, 7.0111996e-01],\n",
       "       [1.2681215e-02, 9.8731881e-01],\n",
       "       [2.4252464e-03, 9.9757475e-01],\n",
       "       [8.7468891e-04, 9.9912530e-01]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_babe_ruth = X_all[np.where(player_ids_all == 'ruthba01')]\n",
    "lstm.predict(X_babe_ruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.42105263157894735, 38),\n",
       "  (0.4594594594594595, 37),\n",
       "  (0.4864864864864865, 37),\n",
       "  (0.4864864864864865, 37),\n",
       "  (0.4864864864864865, 37),\n",
       "  (0.4594594594594595, 37),\n",
       "  (0.43243243243243246, 37),\n",
       "  (0.40540540540540543, 37),\n",
       "  (0.3611111111111111, 36),\n",
       "  (0.3333333333333333, 36),\n",
       "  (0.2857142857142857, 35),\n",
       "  (0.2857142857142857, 35),\n",
       "  (0.29411764705882354, 34),\n",
       "  (0.35294117647058826, 34),\n",
       "  (0.3333333333333333, 33),\n",
       "  (0.25806451612903225, 31),\n",
       "  (0.2692307692307692, 26),\n",
       "  (0.2857142857142857, 21),\n",
       "  (0.3125, 16),\n",
       "  (0.25, 12),\n",
       "  (0.2857142857142857, 7),\n",
       "  (0.0, 4),\n",
       "  (0.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0),\n",
       "  (None, 0)],\n",
       " [(0.9917555771096024, 2062),\n",
       "  (0.9846449136276392, 1563),\n",
       "  (0.9780907668231612, 1278),\n",
       "  (0.9707762557077626, 1095),\n",
       "  (0.9656607700312175, 961),\n",
       "  (0.9529964747356052, 851),\n",
       "  (0.9400544959128065, 734),\n",
       "  (0.9449685534591195, 636),\n",
       "  (0.9406474820143885, 556),\n",
       "  (0.9344978165938864, 458),\n",
       "  (0.9246753246753247, 385),\n",
       "  (0.9223300970873787, 309),\n",
       "  (0.9156118143459916, 237),\n",
       "  (0.9222222222222223, 180),\n",
       "  (0.9259259259259259, 135),\n",
       "  (0.9326923076923077, 104),\n",
       "  (0.9333333333333333, 75),\n",
       "  (0.9166666666666666, 48),\n",
       "  (0.8888888888888888, 27),\n",
       "  (1.0, 15),\n",
       "  (1.0, 6),\n",
       "  (1.0, 6),\n",
       "  (1.0, 2),\n",
       "  (1.0, 1),\n",
       "  (None, 0),\n",
       "  (None, 0)])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_scores_lstm, zeros_scores_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99811906,\n",
       " 0.9997349,\n",
       " 0.99912983,\n",
       " 0.999557,\n",
       " 0.9969489,\n",
       " 0.9991829,\n",
       " 0.9981535,\n",
       " 0.989467,\n",
       " 0.9898754,\n",
       " 0.9688486,\n",
       " 0.9715613,\n",
       " 0.942761,\n",
       " 0.9331082,\n",
       " 0.92390203,\n",
       " 0.9329607,\n",
       " 0.9088898,\n",
       " 0.897143,\n",
       " 0.94207376,\n",
       " 0.90502095,\n",
       " 0.9022516,\n",
       " 0.9083192,\n",
       " 0.7924831,\n",
       " 0.9861785]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.max(axis=1).mean(axis=0) for x in ones_preds_lstm if x is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn(knn, X_test, y_test):\n",
    "    ones_preds, zeros_preds = None, None\n",
    "    try:\n",
    "        ones_preds = knn.predict([X_test[i] for i in np.where(y_test == 1)[0]])\n",
    "        print(np.sum(ones_preds) / len(ones_preds))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        zeros_preds = knn.predict([X_test[i] for i in np.where(y_test == 0)[0]])\n",
    "        print(np.sum(1-zeros_preds) / len(zeros_preds))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ones_preds, zeros_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 big knn (0-padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eval on players at end of career\n",
    "on 10% of test zeros:\n",
    "10% of train 0s: 100% 1s, 94% 0s  \n",
    "50% of train 0s: ??% 1s, 97% 0s  \n",
    "75% of train 0s: ??% 1s, ??% 0s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_end_career_knn(X_train, y_train, X_test, y_test, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=1, test_zeros_ratio=1, end_careers=True):\n",
    "    if train_zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_train_0s = np.where(y_train == 0)[0]\n",
    "        idxs_train_1s = np.where(y_train == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_train_0s, size=int(len(idxs_train_0s) * train_zeros_ratio), replace=False)\n",
    "        X_train_ratio_0s = [X_train[i] for i in ratio_0s] + [X_train[i] for i in idxs_train_1s]\n",
    "        y_train_ratio_0s = [y_train[i] for i in ratio_0s] + [y_train[i] for i in idxs_train_1s]\n",
    "    else:\n",
    "        X_train_ratio_0s = X_train\n",
    "        y_train_ratio_0s = y_train\n",
    "\n",
    "    knn_all = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "    knn_all.fit(X_train_ratio_0s, y_train_ratio_0s)\n",
    "    \n",
    "    if end_careers:\n",
    "        player_career_lengths = agg_df.groupby('player_id')['years_played'].max().to_dict()\n",
    "        test_idxs_full_careers = [i for i in range(len(X_test)) if player_career_lengths[test_player_ids[i]] == test_years_played[i]]\n",
    "        display(len(test_idxs_full_careers) / len(X_test))\n",
    "\n",
    "        X_test_full_careers, y_test_full_careers = X_test[test_idxs_full_careers], y_test[test_idxs_full_careers]\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_0s = np.where(y_test_full_careers==0)[0]\n",
    "        np.random.seed(1)\n",
    "        idxs_sample_0s = np.random.choice(test_0s, size=int(len(test_0s) * test_zeros_ratio))\n",
    "        \n",
    "        idxs = np.concatenate((idxs_sample_0s, np.where(y_test_full_careers==1)[0]))\n",
    "#         print(idxs_sample_0s)\n",
    "        print(idxs)\n",
    "        eval_knn(knn_all, X_test_full_careers[idxs], y_test_full_careers[idxs])\n",
    "    else:\n",
    "        eval_knn(knn_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17418235877106045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1077  241 1112  920  726  860  975  148  131  760  518 1322 1219 1317\n",
      " 1295  364  929  477  922  259  678  406  572  590 1256 1017  764 1126\n",
      "  145 1047  326  842 1354  523  323  215 1305  739  637  439  643  465\n",
      "  552 1111 1354  525  979  804  506 1083 1066 1377  631  897 1338   15\n",
      " 1104  202   25 1323 1062 1015 1167 1320 1397  159  948  320  605 1207\n",
      "  658 1329 1320  762 1127  250 1389  596 1231 1343  943 1192  705 1362\n",
      "  910 1294  470  574  478  153  726  270   79  723 1115 1373 1083  542\n",
      "  885  979  579  216   98  276 1050  286  862  903  156  424 1181 1234\n",
      "  616  498  156 1379  897  878  132  625  273  498  479 1239  717  334\n",
      "  181 1055  915  174   20  640  285  494  636  619 1050 1136   64   74\n",
      "  133  144  180  184  245  398  450  511  706  778  837  881  916  990\n",
      " 1148]\n",
      "1.0\n",
      "0.9710144927536232\n"
     ]
    }
   ],
   "source": [
    "eval_end_career_knn(X_train, y_train, X_test, y_test, agg_df, train_player_ids, test_player_ids, train_years_played, test_years_played, train_zeros_ratio=0.25, test_zeros_ratio=0.1, end_careers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn on specific year of careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_year_knn(yr, X_train, y_train, X_test, y_test, idx_train_by_year, idx_test_by_year, zeros_ratio=1):\n",
    "    idxs_train_yr, idxs_test_yr = np.array(idx_train_by_year[yr]), np.array(idx_test_by_year[yr])\n",
    "    \n",
    "    X_train_yr = [X_train_unpad[i] for i in idx_train_by_year[yr]]\n",
    "    y_train_yr = y_train[idx_train_by_year[yr]]\n",
    "    X_test_yr = [X_test_unpad[i] for i in idx_test_by_year[yr]]\n",
    "    y_test_yr = y_test[idx_test_by_year[yr]]\n",
    "    \n",
    "    if zeros_ratio != 1:\n",
    "        np.random.seed(1)\n",
    "        idxs_yr_train_0s = np.where(y_train_yr == 0)[0]\n",
    "        idxs_yr_train_1s = np.where(y_train_yr == 1)[0]\n",
    "        ratio_0s = np.random.choice(idxs_yr_train_0s, size=int(len(idxs_yr_train_0s) * zeros_ratio), replace=False)\n",
    "        X_train_yr_ratio_0s = [X_train_yr[i] for i in ratio_0s] + [X_train_yr[i] for i in idxs_yr_train_1s]\n",
    "        y_train_yr_ratio_0s = [y_train_yr[i] for i in ratio_0s] + [y_train_yr[i] for i in idxs_yr_train_1s]\n",
    "    else:\n",
    "        X_train_yr_ratio_0s = X_train_yr\n",
    "        y_train_yr_ratio_0s = y_train_yr\n",
    "    \n",
    "    display(np.where(y_test_yr == 1)[0])\n",
    "    \n",
    "    knn_yr = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "    knn_yr.fit(X_train_yr_ratio_0s, y_train_yr_ratio_0s)\n",
    "    \n",
    "    eval_knn(knn_yr, X_test_yr, y_test_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  4,  5,  7,  8,  9, 10, 11, 13])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.75\n"
     ]
    }
   ],
   "source": [
    "eval_year_knn(20, X_train, y_train, X_test, y_test, idx_train_by_year, idx_test_by_year, zeros_ratio=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
